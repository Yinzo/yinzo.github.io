<!DOCTYPE html>
<html lang="zh-CN">

<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<meta http-equiv="X-UA-Compatible" content="ie=edge">

<meta itemprop="name" content="CS229 学习笔记 Part 2">
<meta itemprop="description" content="判别式和生成式 对于一个分类任务，判别式和生成式分别代表了两种不同的思路： 判别式 通过直接从输入数据中学习，得到一个『特定输入对应的实际类别』的">


<meta itemprop="datePublished" content="2017-06-07T00:20:00&#43;08:00" />
<meta itemprop="dateModified" content="2017-06-07T00:20:00&#43;08:00" />
<meta itemprop="wordCount" content="2348">



<meta itemprop="keywords" content="Machine Learning," />
<meta property="og:title" content="CS229 学习笔记 Part 2" />
<meta property="og:description" content="判别式和生成式 对于一个分类任务，判别式和生成式分别代表了两种不同的思路： 判别式 通过直接从输入数据中学习，得到一个『特定输入对应的实际类别』的" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://yinzo.github.io/posts/cs229-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-part-2/" />
<meta property="article:published_time" content="2017-06-07T00:20:00&#43;08:00"/>
<meta property="article:modified_time" content="2017-06-07T00:20:00&#43;08:00"/>
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="CS229 学习笔记 Part 2"/>
<meta name="twitter:description" content="判别式和生成式 对于一个分类任务，判别式和生成式分别代表了两种不同的思路： 判别式 通过直接从输入数据中学习，得到一个『特定输入对应的实际类别』的"/>

	<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
	<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
	<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
	<link rel="manifest" href="/site.webmanifest">
	<link rel="mask-icon" href="/safari-pinned-tab.svg" color="">
	<link rel="shortcut icon" href="/favicon.ico">

	<title>CS229 学习笔记 Part 2</title>
	<link rel="stylesheet" href="https://yinzo.github.io/css/style.min.20e6e5df1f989a2a36ed7cbce604b2672cfea0e8acef9930825ffb5f85914012.css" integrity="sha256-IObl3x+Ymio27Xy85gSyZyz+oOis75kwgl/7X4WRQBI=" crossorigin="anonymous">
	
</head>

<body id="page">
	
	<header id="site-header" class="animated slideInUp faster">
		<div class="hdr-wrapper section-inner">
			<div class="hdr-left">
				<div class="site-branding">
					<a href="https://yinzo.github.io/">雪地</a>
				</div>
				<nav class="site-nav hide-in-mobile">
					
				<a href="https://yinzo.github.io/posts/">Posts</a>

				</nav>
			</div>
			<div class="hdr-right hdr-icons">
				<button id="toc-btn" class="hdr-btn desktop-only-ib" title="Table of Contents"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-list"><line x1="8" y1="6" x2="21" y2="6"></line><line x1="8" y1="12" x2="21" y2="12"></line><line x1="8" y1="18" x2="21" y2="18"></line><line x1="3" y1="6" x2="3" y2="6"></line><line x1="3" y1="12" x2="3" y2="12"></line><line x1="3" y1="18" x2="3" y2="18"></line></svg></button><button id="menu-btn" class="hdr-btn" title="Menu"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu"><line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line></svg></button>
			</div>
		</div>
	</header>
	<div id="mobile-menu" class="animated fast">
		<ul>
			<li><a href="https://yinzo.github.io/posts/">Posts</a></li>
		</ul>
	</div>


	<main class="site-main section-inner animated fadeIn faster">
		<article class="thin">
			<header class="post-header">
				<div class="post-meta"><span>Jun 7, 2017</span></div>
				<h1>CS229 学习笔记 Part 2</h1>
			</header>
			<div class="content">
				<h2 id="toc_0">判别式和生成式<a href="#toc_0" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h2>

<p>对于一个分类任务，判别式和生成式分别代表了两种不同的思路：</p>

<h3 id="toc_1">判别式<a href="#toc_1" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h3>

<p>通过直接从输入数据中学习，得到一个『特定输入对应的实际类别』的概率模型，模型的参数为 $\theta$ 。即学习建模 $p(y\mid x)$</p>

<h3 id="toc_2">生成式<a href="#toc_2" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h3>

<p>通过对每一个类进行建模，然后就可以通过条件概率算出输入的数据更可能由哪一类生成。即学习建模 $p(x\mid y)$ 和 $p(y)$ ，然后计算 $$\arg\max\limits_y\frac{p(x \mid y)p(y)}{p(x)}$$</p>

<p>并且实际计算中，分母 $p(x)$ 并不会影响各个类别概率的排序，所以最终简化成 $$\arg\max\limits_y p(x \mid y)p(y)​$$</p>

<h2 id="toc_3">Gaussian discriminant analysis<a href="#toc_3" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h2>

<p>作为生成式模型的第一个例子，它假设数据的分布 $p(x\mid y)$ 是多元高斯分布 (multivariate normal distribution)，分类结果为二分类，即 $y \sim \mathrm{Bernoulli}(\phi)$。</p>

<p>根据生成式模型的思路，它通过训练数据，计算出两个类的隐含分布——多元高斯分布的参数 $\mu_0, \mu_1,\Sigma$ （需要注意的是，这里对于两个多元正态分布的 $\Sigma$，我们使用的是一个公共的参数，也就是我们假设两个分布的『形状』是一样的），以及对于分类结果的伯努利分布参数 $\phi$</p>

<p>根据定义，我们可以得到以下模型</p>

<p>$$p(y) = \phi^y(1-\phi)^{1-y}$$</p>

<p>$$p(x\mid y=0) = \frac{1}{(2\pi)^{n/2}|\Sigma|^{1/ 2}} \exp\left(-\frac{1}{2}(x-\mu_0)^T\Sigma^{-1}(x-\mu_0)\right)$$</p>

<p>$$p(x\mid y=1) = \frac{1}{(2\pi)^{n/2}|\Sigma|^{1/ 2}} \exp\left(-\frac{1}{2}(x-\mu_1)^T\Sigma^{-1}(x-\mu_1)\right)$$</p>

<p>接下来开始估计各个参数的值。我们使用一个新的似然函数 <strong>Joint likelihood</strong></p>

<p>$$\ell(\phi, \mu_0, \mu<em>1, \Sigma) = log \prod^m</em>{i=1} p(x^{(i)}, y^{(i)}; \phi, \mu_0, \mu_1, \Sigma)$$</p>

<p>$$\phantom{ \ell(\phi, \mu_0, \mu<em>1, \Sigma)} = log \prod^m</em>{i=1} p(x^{(i)}\mid y^{(i)}; \mu_0, \mu_1, \Sigma)p(y^{(i)};\phi)$$</p>

<p>通过最大化此似然函数，我们能够得到以上几个参数的估计值</p>

<p>$$\phi = \frac{1}{m}\sum^m_{i=1}1{y^{(i)}=1}$$</p>

<p>$$\mu<em>0 = \frac{\sum^m</em>{i=1}1{y^{(i)} = 0}x^{(i)}}{\sum^m_{i=1}1{y^{(i)} = 0}}$$</p>

<p>$$\mu<em>1 = \frac{\sum^m</em>{i=1}1{y^{(i)} = 1}x^{(i)}}{\sum^m_{i=1}1{y^{(i)} = 1}}$$</p>

<p>$$\Sigma = \frac{1}{m}\sum^m<em>{i=1}(x^{(i)}-\mu</em>{y^{(i)}})(x^{(i)}-\mu_{y^{(i)}})^T$$</p>

<p>而 GDA 的判别公式则是作为作业的一部分自行完成。</p>

<h2 id="toc_4">讨论：GDA 和 Logistic 回归<a href="#toc_4" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h2>

<p>GDA 的判别公式能够化为以下形式
$$p(y=1\mid x;\phi, \Sigma, \mu_0, \mu_1) = \frac{1}{1+\exp(-\theta^Tx)}$$</p>

<p>也就是 Logistic 回归的形式。（这个公式转化的具体过程是课后习题的一部分）</p>

<p>其中 $\theta$ 是关于 $\phi,\Sigma,\mu_0,\mu_1$ 的函数。那么 GDA 和 Logistic 回归（下称 LR）的区别在哪里呢？</p>

<p>假设 $p(x\mid y)$ 满足多元高斯分布，那么 $p(y\mid x)$ 能够写成 logistic 函数的形式。但是，反之并不成立。$p(y\mid x)$ 能够写成 logistic 函数的形式并不意味着 $p(x\mid y)$ 符合多元高斯分布。这说明，GDA 做出了一个更强的假设 (stronger modeling assumption)。</p>

<p>并且，当这个假设符合现实（ $p(x\mid y)$ 符合多元高斯分布 ），并且在训练集足够大的情况下，没有其他算法优于 GDA1。而且通常来说，对于一个较小的训练集，我们通常会觉得 GDA 会表现的更好。</p>

<p>反过来说，对于使用了较弱假设的 LR，它拥有更强的鲁棒性，对于错误的模型假设也更不敏感。对 $p(x\mid y)$ 分布的假设，有很多种情况能够使得 $p(y\mid x)$ 可以化为 Logistic 函数的形式。比如说，$x \mid y = 0$ 和 $x \mid y = 1$ 分别符合两个独立的泊松分布时既是如此。</p>

<h2 id="toc_5">朴素贝叶斯<a href="#toc_5" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h2>

<p>对于一个文本分类问题，使用50000个词的简化词袋模型时，我们的目标是对 $p(x<em>1,\cdots,x</em>{50000}\mid y)$ 构建出最准确的模型。</p>

<p>$$p(x<em>1,\cdots,x</em>{50000}\mid y)$$</p>

<p>$$ = p(x_1\mid y)p(x_2\mid y,x_1)p(x_3\mid y,x_1,x<em>2)\cdots p(x</em>{50000}\mid y,x_1,x<em>2,\cdots,x</em>{49999})$$</p>

<p>此时的式子称为贝叶斯分类器。而朴素贝叶斯和贝叶斯的区别在于哪里呢？关键就在于以下假设：</p>

<p><strong>朴素贝叶斯假设：假设 $x_i$ 条件独立于 $y_i$</strong></p>

<p>则原概率公式</p>

<p>$$ = p(x_1\mid y)p(x_2\mid y)p(x<em>3\mid y)\cdots p(x</em>{50000}\mid y)$$</p>

<p>此时的式子就称为朴素贝叶斯分类器了。虽然朴素贝叶斯假设是一个很强的假设 (strong assumption)，但是它出人意料的在很多问题上都表现的不错。
使用朴素贝叶斯概率公式，则词袋中的每个词，对于每种文本分类都属于一个独立参数的伯努利分布。即此例子中，词袋大小50000，2种文本分类，于是共有 100,000 个伯努利分布参数需要估计，以及一个对于类别 y 的伯努利分布参数 $\phi_y$。</p>

<p>我们使用 Joint likelihood 作为目标函数</p>

<p>$$ \mathcal{L}(\phi<em>y, \phi</em>{j\mid y=0}, \phi<em>{j\mid y=1}) = \prod^m</em>{i=1}p(x^{(i)}, y^{(i)})$$</p>

<p>最大化似然函数得到各个参数的估计</p>

<p>$$j \in {1,2,\cdots,50000}$$</p>

<p>$$ \phi<em>{j\mid y=1} = \frac{\sum^m</em>{i=1}\operatorname{1}{x<em>j^{(i)} = 1 \wedge y^{(i)} = 1 }}{\sum^m</em>{i=1}\operatorname{1}{ y^{(i)} = 1 }} $$</p>

<p>$$\phi<em>{j\mid y=0} = \frac{\sum^m</em>{i=1}\operatorname{1}{x<em>j^{(i)} = 1 \wedge y^{(i)} = 0 }}{\sum^m</em>{i=1}\operatorname{1}{ y^{(i)} = 0 }}$$</p>

<p>$$\phi<em>y = \frac{\sum^m</em>{i=1}\operatorname{1}{ y^{(i)} = 1 }}{m}$$</p>

<p>朴素贝叶斯的判别公式如下：</p>

<p>$$p(y=1\mid x) = \frac{p(x\mid y =1)p(y=1)}{p(x)}$$</p>

<p>$$ = \frac{(\prod^n_{i=1}p(x<em>i|y=1))p(y=1)}{(\prod^n</em>{i=1}p(x<em>i|y=1))p(y=1)+(\prod^n</em>{i=1}p(x_i|y=0))p(y=0)}$$</p>

<p>最后，我们能够很容易的想到，可以将 $x_i$ 的取值从二值变为多值，就成为了这个算法的泛化。为了做到这一点，我们只需要将对 $p(x_i\mid y)$ 假设的伯努利分布，替换成多项式分布即可。如果原始属性是连续值，我们也可以通过分段的办法，将他离散化。之后，就可以仿照我们上述的过程来使用朴素贝叶斯算法了。当原始的连续属性使用多元正态分布不能很好的建模时，将他离散化后使用朴素贝叶斯通常能取得更好的效果。</p>

<h3 id="toc_6">拉普拉斯平滑<a href="#toc_6" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h3>

<p>上述标准的朴素贝叶斯通常情况下效果都很好，但是在一些特殊情况下会出现奇怪的情况。比如说，当你的分类器遇到了一个从来没有见过的词（不存在于训练数据中）的时候，对于这个词两个类别的概率都会等于零，并且由于累乘的结果，会使得整个输出都变为零。这显然不合理，所以这就是拉普拉斯平滑要解决的事情。</p>

<p>原理很简单，我们对于一个多项式分布输入的类别概率计算公式如下</p>

<p>$$p(z=j) = \phi<em>j = \frac{\sum^m</em>{i=1} \operatorname{1}{z^{(i)}=j}}{m}$$</p>

<p>我们想要让这个式子不等于零，很直觉的办法是在分子上加上一个很小的数。所以我们在分子上加一个 1。但是这还不够，我们需要让多项式分布的各个类整体概率和仍然为 1，即 $\sum^k_{j=1}\phi_j = 1$ 。所以我们分母也需要稍作改动，最终我们得到
$$p(z=j) = \phi<em>j = \frac{\sum^m</em>{i=1} \operatorname{1}{z^{(i)}=j}+1}{m+k}$$</p>

<p>读者可以自己验算 $\sum^k_{j=1}\phi_j = 1$</p>

<h3 id="toc_7">用于文本分类的事件模型<a href="#toc_7" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h3>

<p>之前的模型我们称为『多变量伯努利分布事件模型』<sup id="fnref2"><a href="#fn2" rel="footnote">2</a></sup>，而对于文本分类的任务，接下来这个模型通常能够取得更好的效果，称为『多项式分布事件模型』<sup id="fnref3"><a href="#fn3" rel="footnote">3</a></sup>。</p>

<p>在这个模型中，一个由 n 个词组成的文本段将化为一个 n 维向量，每一维符合都一个相同的多项式分布，多项式分布一个选项对应一个特定的词。比如一个电子邮件内容为『快来 购买……』，在多项式分布中，快来对应的类别编号为33，购买的类别编号为580，则形成的输入向量就是 [33, 580, …]</p>

<p>文本段中每一个词的分布都来自同一个多项式分布，需要注意的是，词在文中的位置并不影响他的取值分布。</p>

<p>则似然函数定义如下
$$\mathcal{L}(\phi, \phi<em>{k\mid y=0}, \phi</em>{k\mid y=1}) = \prod^m_{i=1}p(x^{(i)}，y^{(i)})$$</p>

<p>$$= \prod^m_{i=1}\left( \prod^{n<em>i}</em>{j=1}p(x<em>j^{(i)}\mid y;\phi</em>{k\mid y=0},\phi_{k\mid y=1}) \right)p(y^{(i)};\phi_y)$$</p>

<p>最大化似然函数得到参数估计</p>

<p>$$\phi<em>{k\mid y=1} = \frac{\sum^m</em>{i=1}\sum^{n<em>i}</em>{j=1} \operatorname{1}{x<em>j^{(i)} = k\wedge y^{(i)} = 1 } }{\sum^m</em>{i=1} \operatorname{1}{ y^{(i)} = 1} n_i}$$</p>

<p>$$\phi<em>{k\mid y=0} = \frac{\sum^m</em>{i=1}\sum^{n<em>i}</em>{j=1} \operatorname{1}{x<em>j^{(i)} = k\wedge y^{(i)} = 0 } }{\sum^m</em>{i=1} \operatorname{1}{ y^{(i)} = 0} n_i}​$$</p>

<p>$$\phi<em>y = \frac{\sum^m</em>{i=1}\operatorname{1}{y^{(i)} = 1}}{m}$$</p>

<p>多项式分布事件模型和之前的模型的不同点在于，新模型除了统计某一个词是否出现，还考虑了某一个词出现的次数。</p>

<div class="footnotes">
<hr/>
<ol>
<li id="fn1">
<p>in the limit of vary large training sets (large m), there is no algorithm that is strictly better than GDA.&nbsp;<a href="#fnref1" rev="footnote">↩</a></p>
</li>
<li id="fn2">
<p>multi-variate Bernoulli event model&nbsp;<a href="#fnref2" rev="footnote">↩</a></p>
</li>
<li id="fn3">
<p>multinomial event model&nbsp;<a href="#fnref3" rev="footnote">↩</a></p>
</li>
</ol>
</div>

			</div>
			<hr class="post-end">
			<footer class="post-info">
				<p>
					<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-tag meta-icon"><path d="M20.59 13.41l-7.17 7.17a2 2 0 0 1-2.83 0L2 12V2h10l8.59 8.59a2 2 0 0 1 0 2.82z"></path><line x1="7" y1="7" x2="7" y2="7"></line></svg><span class="tag"><a href="https://yinzo.github.io/tags/machine-learning">Machine Learning</a></span>
				</p>
				<p><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file-text"><path d="M14 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V8z"></path><polyline points="14 2 14 8 20 8"></polyline><line x1="16" y1="13" x2="8" y2="13"></line><line x1="16" y1="17" x2="8" y2="17"></line><polyline points="10 9 9 9 8 9"></polyline></svg>2348 Words</p>
				<p><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-calendar"><rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect><line x1="16" y1="2" x2="16" y2="6"></line><line x1="8" y1="2" x2="8" y2="6"></line><line x1="3" y1="10" x2="21" y2="10"></line></svg>2017-06-07 00:20 &#43;0800</p>
			</footer>
		</article>
		<aside id="toc">
			<div class="toc-title">Table of Contents</div>
			
		</aside>
		<div class="post-nav thin">
			<a class="next-post" href="https://yinzo.github.io/posts/cs229-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-part-3/">
				<span class="post-nav-label"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-arrow-left"><line x1="19" y1="12" x2="5" y2="12"></line><polyline points="12 19 5 12 12 5"></polyline></svg>&nbsp;Newer</span><br><span>CS229 学习笔记 Part 3</span>
			</a>
			<a class="prev-post" href="https://yinzo.github.io/posts/cs229-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-part-1/">
				<span class="post-nav-label">Older&nbsp;<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-arrow-right"><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg></span><br><span>CS229 学习笔记 Part 1</span>
			</a>
		</div>
		<div id="comments" class="thin">
<script src='//unpkg.com/valine/dist/Valine.min.js'></script>
<p id="/posts/cs229-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-part-2/" class="leancloud_visitors" data-flag-title="CS229 学习笔记 Part 2">
    <span class="post-meta-item-text">阅读量 </span>
    <span class="leancloud-visitors-count">-</span>
</p>
<div id="vcomments" sty ></div>
<style>
.v .vbtn {
    background: transparent !important;
    border: 2px solid #c6cddb !important;
    color: #c6cddb !important;
}

.v .vinfo .vcount .vnum {
    color: #c6cddb !important;
}

.v .vinfo .col {
    color: #c6cddb !important;
}

.v .vlist .vcard .vh .vmeta .vat {
    color: #c6cddb !important;
}

.v p, .v strong {
    color: #c6cddb !important;
}

.v code {
    font-weight: bold !important;
    font-size: 0.8rem !important;
}

.v pre {
    font-size: 1rem !important;
    font-weight: bold !important;
    background: #2c3e50 !important;
}

.v li {
    color: #c6cddb !important;
    margin-left: .5rem !important;
}

.v a {
    color: #1abc9c !important;
}

.v .vwrap .vheader .vinput {
    border-bottom: 1px dashed #c6cddb !important;
}

.v .vwrap {
    border: 2px solid #c6cddb !important;
}

.v .vinput {
    color: #c6cddb !important;
}

.v .veditor {
    color: #c6cddb !important;
}

.v .vwrap .vedit .vctrl span {
    color: #c6cddb !important;
}

.v .vwrap .vcontrol .col svg {
    color: #c6cddb !important;
}

.v .vlist .vcard .vhead .vsys {
    background: transparent !important;
    border: 1px solid #c6cddb!important;
    padding: 0 .4rem 0 .4rem !important;
    color: #c6cddb !important;
}

.v .vlist .vcard .vquote {
    border-left: 0px !important;
}

.v .vlist .vcard .vh {
    border-bottom: 0px !important;
}

.v .power {
    color: #c6cddb !important;
}

.v .vlist .vcard .vh .vtime {
    color: #c6cddb !important;
}

.v .vlist .vcard .vcontent {
    color: #c6cddb !important;
}

::-moz-placeholder { color: #ccc; }
::-webkit-input-placeholder { color:#ccc; }
:-ms-input-placeholder { color:#ccc; }
</style>
<script>    
    new Valine({
        el:'#vcomments',
        appId: 'wNSjixVlMTvSPXjMubNsdiy5-9Nh9j0Va',
        appKey: 'ygUBd8larhetzhyeV3sLpQ5q',
        visitor: 'true'
    })
</script></div>
	</main>

	<footer id="site-footer" class="section-inner thin animated fadeIn faster">
		<p>&copy; 2020 <a href="https://yinzo.github.io/">Yinzo</a></p>
		<p>
			Made with <a href="https://gohugo.io/" target="_blank" rel="noopener">Hugo</a> &#183; Theme <a href="https://github.com/Track3/hermit" target="_blank" rel="noopener">Hermit</a> &#183; <a href="https://yinzo.github.io/posts/index.xml" target="_blank" title="rss"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-rss"><path d="M4 11a9 9 0 0 1 9 9"></path><path d="M4 4a16 16 0 0 1 16 16"></path><circle cx="5" cy="19" r="1"></circle></svg></a>
		</p>
	</footer>
	<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_SVG"></script>
	<script type="text/x-mathjax-config">
		MathJax.Hub.Config({
		  tex2jax: {
			inlineMath: [ ['$','$'], ["\\(","\\)"] ],
			processEscapes: true
		  }
		});
	  </script>


	<script src="https://yinzo.github.io/js/bundle.min.490e43e5af6db5906f28afa49a4e16bf9f626b758e3fca92f146b870eb94bb37.js" integrity="sha256-SQ5D5a9ttZBvKK+kmk4Wv59ia3WOP8qS8Ua4cOuUuzc=" crossorigin="anonymous"></script>
	

</body>

</html>
